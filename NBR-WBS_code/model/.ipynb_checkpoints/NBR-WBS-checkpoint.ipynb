{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93f6a871",
   "metadata": {},
   "source": [
    "# 下載套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "307637fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import nn, matmul, softmax\n",
    "from torch.nn.init import xavier_uniform_\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "import gzip\n",
    "import gc\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddf51a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd5bc55",
   "metadata": {},
   "source": [
    "# 參數設置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e5878e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超參數\n",
    "EPOCHS = 25\n",
    "LEARNING_RATE = 0.0001                 # Learning_rate\n",
    "BATCH_SIZE = 8\n",
    "BETA = 0.5\n",
    "ALPHA = 0.1\n",
    "EMBEDDING_DIMENSION = 32               # 嵌入維度\n",
    "MODEL_DIMENSION = EMBEDDING_DIMENSION  # 模型維度\n",
    "HIDDEN_DIMENSION = 128                 # MLP 隱藏層維度\n",
    "HIDDEN_SIZE = 16                       # LSTM 隱藏層維度\n",
    "NUM_HEAD = 4\n",
    "NUM_LAYER = 4\n",
    "\n",
    "isI2V = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25a38a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料集\n",
    "DATASET_NAME = \"TaFeng\"     # 讀取TaFeng資料\n",
    "# DATASET_NAME = \"Dunnhumby\"  # 讀取Dunnhumby資料\n",
    "# DATASET_NAME = \"Instacart\"  # 讀取Instacart資料"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f60362b",
   "metadata": {},
   "source": [
    "# 匯入檔案\n",
    "- item2Vec_{dataset}.32d.model\n",
    "- user_cart_itemid_list.gz\n",
    "- {dataset}_clean.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b38e8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15764, 32])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load word2Vec pre_train model\n",
    "model_filename = f\"../preprocessing-data/item2vec_models/item2vec_{DATASET_NAME}.{EMBEDDING_DIMENSION}d.model\"\n",
    "# {DATASET}\n",
    "with open(model_filename, \"rb\") as fp:\n",
    "    model = pickle.load(fp)\n",
    "weights = torch.FloatTensor(model.wv.vectors)\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80368ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1113,\n",
       "  [[0, 1, 2], [3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15]],\n",
       "  [3, 6, 7]),\n",
       " (5241,\n",
       "  [[16, 17, 18, 19, 20, 21],\n",
       "   [22, 23, 24, 25, 26, 27, 28, 29, 30, 31],\n",
       "   [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47],\n",
       "   [48, 49, 50, 51, 52]],\n",
       "  [6, 10, 16, 5])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# {DATASET} user_cart_itemid_list 用戶id, 購物籃時間差(不會使用到), 此用戶的購物籃串列(每個串列包含多項目)。\n",
    "with gzip.open(f\"../preprocessing-data/{DATASET_NAME}_user_cart_itemid_list.gz\", \"rb\") as fp:\n",
    "    user_cart_itemid_list = pickle.load(fp)\n",
    "user_cart_itemid_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1322afac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load {DATASET} confidences_Matrix\n",
    "with gzip.open(f\"../preprocessing-data/confidences/{DATASET_NAME}_confidences_array.gz\", \"rb\") as fp:\n",
    "    confidences_array = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b34ae99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUSTOMER_ID</th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>TRANSACTION_DT</th>\n",
       "      <th>CART_ID</th>\n",
       "      <th>NEW_ITEM_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1113</td>\n",
       "      <td>4902105011621</td>\n",
       "      <td>2000-11-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1113</td>\n",
       "      <td>7616100830794</td>\n",
       "      <td>2000-11-26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1113</td>\n",
       "      <td>4710892632017</td>\n",
       "      <td>2000-11-26</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1113</td>\n",
       "      <td>4710905340113</td>\n",
       "      <td>2000-11-27</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1113</td>\n",
       "      <td>4717362901277</td>\n",
       "      <td>2000-11-27</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533054</th>\n",
       "      <td>20002000</td>\n",
       "      <td>4710339772139</td>\n",
       "      <td>2001-01-20</td>\n",
       "      <td>62360</td>\n",
       "      <td>4546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533055</th>\n",
       "      <td>20002000</td>\n",
       "      <td>20513184</td>\n",
       "      <td>2001-01-20</td>\n",
       "      <td>62360</td>\n",
       "      <td>1351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533056</th>\n",
       "      <td>20002000</td>\n",
       "      <td>4714800731229</td>\n",
       "      <td>2001-01-20</td>\n",
       "      <td>62360</td>\n",
       "      <td>2946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533057</th>\n",
       "      <td>20002000</td>\n",
       "      <td>4714541091071</td>\n",
       "      <td>2001-01-20</td>\n",
       "      <td>62360</td>\n",
       "      <td>7382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533058</th>\n",
       "      <td>20002000</td>\n",
       "      <td>4710018008634</td>\n",
       "      <td>2001-01-20</td>\n",
       "      <td>62360</td>\n",
       "      <td>2629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>533059 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CUSTOMER_ID     PRODUCT_ID TRANSACTION_DT  CART_ID  NEW_ITEM_ID\n",
       "0              1113  4902105011621     2000-11-26        0            0\n",
       "1              1113  7616100830794     2000-11-26        0            1\n",
       "2              1113  4710892632017     2000-11-26        0            2\n",
       "3              1113  4710905340113     2000-11-27        1            3\n",
       "4              1113  4717362901277     2000-11-27        1            4\n",
       "...             ...            ...            ...      ...          ...\n",
       "533054     20002000  4710339772139     2001-01-20    62360         4546\n",
       "533055     20002000       20513184     2001-01-20    62360         1351\n",
       "533056     20002000  4714800731229     2001-01-20    62360         2946\n",
       "533057     20002000  4714541091071     2001-01-20    62360         7382\n",
       "533058     20002000  4710018008634     2001-01-20    62360         2629\n",
       "\n",
       "[533059 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(f\"../cleaned_dataset/{DATASET_NAME}_clean.csv\")\n",
    "\n",
    "# 最多購物籃\n",
    "max_cart_count = dataset.groupby(\"CUSTOMER_ID\")[\"CART_ID\"].nunique().max()\n",
    "print(max_cart_count)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1949cff4",
   "metadata": {},
   "source": [
    "# 切分資料集\n",
    "- 分成輸入資料與標籤資料\n",
    "- 訓練集:驗證集:測試集 = 8:1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a483ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8523\n",
      "1065\n",
      "1066\n"
     ]
    }
   ],
   "source": [
    "# 切分資料集\n",
    "# train_set_size = int(len(user_cart_itemid_list) * 0.8)\n",
    "# valid_set_size = int(len(user_cart_itemid_list) * 0.1)\n",
    "# test_set_size = len(user_cart_itemid_list)-train_set_size-valid_set_size\n",
    "# train_set, valid_set, test_set = random_split(user_cart_itemid_list, [train_set_size, valid_set_size, test_set_size])\n",
    "# print(len(train_set))\n",
    "# print(len(valid_set))\n",
    "# print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "075d2f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將切割好的資料暫存起來\n",
    "# dataset_folder = f\"../preprocessing-data/{DATASET_NAME}_dataset\"\n",
    "# if not os.path.exists(dataset_folder):\n",
    "#     os.mkdir(dataset_folder)\n",
    "\n",
    "# # 訓練集\n",
    "# filepath = f\"../preprocessing-data/{DATASET_NAME}_dataset/train_set.pkl\"\n",
    "# with open(filepath, \"wb\") as f:\n",
    "#     pickle.dump(train_set, f)\n",
    "# # 驗證集\n",
    "# filepath = f\"../preprocessing-data/{DATASET_NAME}_dataset/valid_set.pkl\"\n",
    "# with open(filepath, \"wb\") as f:\n",
    "#     pickle.dump(valid_set, f)\n",
    "# # 測試集\n",
    "# filepath = f\"../preprocessing-data/{DATASET_NAME}_dataset/test_set.pkl\"\n",
    "# with open(filepath, \"wb\") as f:\n",
    "#     pickle.dump(test_set, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da0fd537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取之前暫存的資料集\n",
    "\n",
    "# # 載入訓練、驗證、測試集\n",
    "# with open(f\"../preprocessing-data/{DATASET_NAME}_dataset/train_set.pkl\", \"rb\") as fp:\n",
    "#     train_set = pickle.load(fp)\n",
    "# with open(f\"../preprocessing-data/{DATASET_NAME}_dataset/valid_set.pkl\", \"rb\") as fp:\n",
    "#     valid_set = pickle.load(fp)\n",
    "# with open(f\"../preprocessing-data/{DATASET_NAME}_dataset/test_set.pkl\", \"rb\") as fp:\n",
    "#     test_set = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab36128",
   "metadata": {},
   "source": [
    "# BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a98a672c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a943efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義資料轉換函數(於collate_batch函式中使用)\n",
    "item_index_pipeline = lambda x : [[model.wv.key_to_index[j] for j in i] for i in x] # 取得購物籃中，項目的索引值(只有使用Item2Vec時會需要)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7137d8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorDataset(Dataset):\n",
    "    # TensorDataset繼承Dataset, 重載__init__, __getitem__, __len__\n",
    "    # 實現將一組Tensor數據封裝成Tensor數據集\n",
    "    # 能夠通過Index得到數據集的數據，能夠通過len，得到數據集大小\n",
    "    def __init__(self, data_tensor):\n",
    "        self.data_tensor = data_tensor\n",
    "    def __getitem__(self, index):\n",
    "        return self.data_tensor[index]\n",
    "    def __len__(self):\n",
    "        return len(self.data_tensor)\n",
    "\n",
    "# 輸出userID, input_list跟label(最後一個購物籃)\n",
    "def collate_batch(batch):\n",
    "    # 使用ID、時間差、訓練的購物籃項目、預測的購物籃項目\n",
    "    userID, input_item_list, label_item_list, input_size_list, label_size_list = [], [], [], [], []\n",
    "    for _user in batch:\n",
    "        #　userID\n",
    "        userID.append(_user[0])\n",
    "        # 所有購物籃的項目ID串列中的最後一個購物籃項目ID\n",
    "        label_item_list.append(torch.tensor(_user[1][-1]))\n",
    "        label_size_list.append(torch.tensor(_user[2][-1]))\n",
    "        \n",
    "        # 不使用Item2Vec進行項目嵌入\n",
    "        if isI2V == 0:\n",
    "            train_list = _user[1][0:-1]\n",
    "        # 使用Item2Vec進行項目嵌入\n",
    "        else:\n",
    "            train_list = item_index_pipeline(_user[1][0:-1])\n",
    "        input_size_list.append(_user[2][0:-1])\n",
    "        \n",
    "        input_item_list.append(train_list) #　所有購物籃的項目ID串列(除了最後一個購物籃)\n",
    "    \n",
    "    return userID, input_item_list, label_item_list, input_size_list, label_size_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d17716b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 轉成 Dataset\n",
    "split_train_ = TensorDataset(train_set)\n",
    "split_valid_ = TensorDataset(valid_set)\n",
    "split_test_ = TensorDataset(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4faf82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch, drop_last=True)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch, drop_last=True)\n",
    "test_dataloader = DataLoader(split_test_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e8f08b",
   "metadata": {},
   "source": [
    "# Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab28e701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用nn.MultiheadAttention\n",
    "# 輸入一個用戶的購物籃，輸出購物籃嵌入\n",
    "class SelfAttention(nn.Module):\n",
    "    #　項目向量維度，輸出模型維度\n",
    "    def __init__(self, embed_dim, model_dim):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.model_dim = model_dim\n",
    "    \n",
    "        # 初始化Q, K, V 矩陣\n",
    "        self.query_matrix = nn.Linear(embed_dim, model_dim)\n",
    "        xavier_uniform_(self.query_matrix.weight)\n",
    "        self.key_matrix = nn.Linear(embed_dim, model_dim)\n",
    "        xavier_uniform_(self.key_matrix.weight)\n",
    "        self.value_matrix = nn.Linear(embed_dim, model_dim)\n",
    "        xavier_uniform_(self.value_matrix.weight)\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim, num_heads=1)\n",
    "    \n",
    "    def forward(self, inputs, attention_mask):\n",
    "        \n",
    "        # 輸入一個項目向量，透過三個可學習的參數矩陣，得到計算所需要的q, k, v\n",
    "        q = self.query_matrix(inputs)\n",
    "        k = self.key_matrix(inputs)\n",
    "        v = self.value_matrix(inputs)\n",
    "        \n",
    "        attn_output, attn_output_weight = self.multihead_attn(q, k, v, key_padding_mask=attention_mask.transpose(0,1))\n",
    "        \n",
    "        output_mean = torch.tensor([[0 for _ in range(MODEL_DIMENSION)] for _ in range(len(attention_mask))], dtype=torch.float).to(device)\n",
    "        for i, cart in enumerate(attention_mask):\n",
    "            for j, mask in enumerate(cart):\n",
    "                if mask == False:\n",
    "                    # 使用最後一個項目最作為輸出\n",
    "                    output_mean[i] = attn_output[i][j]\n",
    "        basket_embedding = output_mean\n",
    "        \n",
    "        return basket_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81dcd9b",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e4204a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = torch.nn.LSTM(input_size, HIDDEN_SIZE, 2)\n",
    "        self.hiddenlayer1 = torch.nn.Linear(max_cart_count * HIDDEN_SIZE, 512)\n",
    "        self.hiddenlayer2 = torch.nn.Linear(512, 512)\n",
    "        self.hiddenlayer3 = torch.nn.Linear(512, 256)\n",
    "        self.hiddenlayer4 = torch.nn.Linear(256, 128)\n",
    "        self.embed = torch.nn.Linear(128, EMBEDDING_DIMENSION)\n",
    "        self.leakyrelu = torch.nn.LeakyReLU()\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        output, (h,c) = self.lstm(inputs)\n",
    "        hidden1 = self.hiddenlayer1(output.view(max_cart_count * HIDDEN_SIZE))\n",
    "        hidden2 = self.hiddenlayer2(hidden1)\n",
    "        hidden3 = self.hiddenlayer3(hidden2)\n",
    "        hidden4 = self.hiddenlayer4(hidden3)\n",
    "        output = self.embed(hidden4)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f200f312",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80a2c0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model:int, dropout, maxlen:int=500):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        # den 是把10000^(2i/d_model)取log_e，前面加負號是求倒數\n",
    "        den = torch.exp(-torch.arange(0, d_model, 2) * math.log(10000) / d_model)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros(maxlen, d_model)\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos*den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos*den)\n",
    "        \n",
    "        pos_embedding = pos_embedding.unsqueeze(0)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\"pos_embedding\", pos_embedding)\n",
    "        \n",
    "    def forward(self, token_embedding):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:, :token_embedding.size(1), :])\n",
    "    \n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, d_model, num_heads=8, num_layers=6):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.pe = PositionalEncoding(d_model=d_model, dropout=0.5, maxlen=max_cart_count)\n",
    "        #　創建Transformer模型\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=num_heads),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        \n",
    "    def forward(self, baskets_embedding):\n",
    "        baskets_embedding_pe = self.pe(baskets_embedding)\n",
    "        \n",
    "        # 購物籃padding的遮罩\n",
    "        padding_mask = ~baskets_embedding.sum(dim=-1).ne(0).transpose(0,1)\n",
    "        \n",
    "        output = self.transformer(baskets_embedding_pe.to(torch.float32), src_key_padding_mask=padding_mask.to(torch.float32))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b9342",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96db71ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPforItem(nn.Module):\n",
    "    def __init__(self, embed_dim, hidden_dim, items_dim):\n",
    "        super(MLPforItem, self).__init__()\n",
    "        # hidden layer\n",
    "        self.hidden = nn.Linear(embed_dim, hidden_dim)\n",
    "        xavier_uniform_(self.hidden.weight)\n",
    "        self.norm = nn.BatchNorm1d(hidden_dim, momentum=0.03)\n",
    "        self.relu = nn.ReLU()\n",
    "        # output layer\n",
    "        self.output = nn.Linear(hidden_dim, items_dim)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        y = self.relu(self.norm(self.hidden(inputs)))\n",
    "        return self.output(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3295318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPforSize(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super(MLPforSize, self).__init__()\n",
    "        # predict layer\n",
    "        self.predict = nn.Linear(embed_dim, 1)\n",
    "        self.leakyrelu = torch.nn.LeakyReLU()\n",
    "    def forward(self, inputs):\n",
    "        output = self.leakyrelu(self.predict(inputs))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dab9aad",
   "metadata": {},
   "source": [
    "# 損失函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "061ed2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE\n",
    "def mean_square_error(prediction, target):\n",
    "    predictions = prediction[0]\n",
    "    targets = torch.tensor([target[0]], dtype=torch.float).to(device)\n",
    "    loss = F.mse_loss(predictions, targets)\n",
    "    for i in range(1, len(prediction)):\n",
    "        predictions = prediction[i]\n",
    "        targets= torch.tensor([target[i]], dtype=torch.float).to(device)\n",
    "        loss += F.mse_loss(predictions, targets)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28cea6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_entropy_loss\n",
    "def cross_entropy_loss(predictions, targets):\n",
    "    # 創建稀疏張量的索引和值\n",
    "    indices = []\n",
    "    values = []\n",
    "    for i, t in enumerate(targets):\n",
    "        for v in t:\n",
    "            indices.append([i, v])\n",
    "            values.append(1)\n",
    "            \n",
    "    # 創建稀疏張量\n",
    "    sparse_targets = torch.sparse_coo_tensor(indices=torch.tensor(indices).t(),\n",
    "                                             values=torch.tensor(values, dtype=torch.float16),\n",
    "                                             size=(len(targets), items_count), device=device)\n",
    "    sparse_targets = sparse_targets.to_dense()\n",
    "    \n",
    "    loss = F.binary_cross_entropy_with_logits(predictions, sparse_targets)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5590d08",
   "metadata": {},
   "source": [
    "# 評估指標"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7cc05c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_metric(result_dict):\n",
    "    assert type(result_dict) == dict\n",
    "    format_str = []\n",
    "    metrics = np.unique([k for k in result_dict.keys()])\n",
    "    for metric in np.sort(metrics):\n",
    "        name = '{}'.format(metric)\n",
    "        m = result_dict[name]\n",
    "        if type(m) is float or type(m) is np.float32 or type(m) is np.float64:\n",
    "            format_str.append(\"{}: {:<.4f}\".format(name, m))\n",
    "        elif type(m) is int or type(m) is np.int32 or type(m) is np.int64:\n",
    "            format_str.append(\"{}: {}\".format(name, m))\n",
    "    return \", \".join(format_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a2e5e0",
   "metadata": {},
   "source": [
    "# F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0a89445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1_score_at_k(predictions, targets, k_list):\n",
    "    \"\"\"\n",
    "    計算 F1-score@K。\n",
    "\n",
    "    Args:\n",
    "        predictions: 二維的預測機率矩陣，大小為 [num_users, num_items]。\n",
    "        targets: 一個包含每個用戶真實標籤的列表，其中每個列表的大小不同。\n",
    "        k_list: 用預測出的K值，計算F1-score@K\n",
    "\n",
    "    Returns:\n",
    "        F1-score@K 分數。\n",
    "    \"\"\"\n",
    "    # 將預測機率矩陣值轉換為 Pytorch 張量\n",
    "    predictions = torch.from_numpy(np.array(predictions, dtype=np.float32))\n",
    "    num_users = len(targets)\n",
    "    f1_score_at_k_eval = dict()\n",
    "    \n",
    "    f1_score_sum = 0.0\n",
    "    for i in range(num_users):\n",
    "        \n",
    "        # 將用戶 i 的真實標籤轉換為 PyTorch 張量。\n",
    "        labels = torch.from_numpy(np.array(targets[i], dtype=np.int64))\n",
    "        # 計算用戶 i 在預測機率矩陣中機率最高的 K 個項目索引\n",
    "        top_k_item_labels = torch.topk(predictions[i], k_list[i])[1]\n",
    "        # 計算用戶 i 的真實標籤和預測標籤的交集 (TP)\n",
    "        true_positives = torch.sum(torch.sum(torch.eq(top_k_item_labels, labels.unsqueeze(1)).to(torch.float32), dim=1)).item()\n",
    "        # 計算用戶 i 的真實標籤和預測標籤的聯集\n",
    "        predicted_positives = k_list[i] # TP+FP\n",
    "        actual_positives = len(labels)  # TP+FN\n",
    "        # 預防 K 預測為0導致 precision 分母為0\n",
    "        if predicted_positives == 0:\n",
    "            precision = 0.0\n",
    "        else:\n",
    "            precision = true_positives / predicted_positives\n",
    "        # 預防實際 K 為0導致 recall 分母為0\n",
    "        if actual_positives == 0:\n",
    "            recall = 0.0\n",
    "        else:\n",
    "            recall = true_positives / actual_positives\n",
    "        # 計算F1-score\n",
    "        if precision + recall == 0:\n",
    "            f1_score = 0.0\n",
    "        else:\n",
    "            f1_score = 2 * precision * recall / (precision + recall)\n",
    "        f1_score_sum += f1_score\n",
    "    # 計算平均 F1-score@K 分數\n",
    "    f1_score_at_k = f1_score_sum / float(num_users)\n",
    "    key = \"{}\".format(\"F1-score\")\n",
    "    f1_score_at_k_eval[key] = f1_score_at_k\n",
    "    \n",
    "    return f1_score_at_k_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a62e151",
   "metadata": {},
   "source": [
    "# NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "655e6035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ndcg_at_k(basket_predictions, basket_targets, size_predictions, size_targets):\n",
    "    \"\"\"\n",
    "    計算 NDCG@K。\n",
    "\n",
    "    Args:\n",
    "        basket_predictions: 預測購物籃項目\n",
    "        bakset_targets: 實際購物籃項目\n",
    "        size_predictions: 預測購物籃大小\n",
    "        size_targets: 實際購物籃大小  \n",
    "\n",
    "    Returns:\n",
    "        NDCG@K 分數。\n",
    "    \"\"\"\n",
    "    # 將預測機率矩陣轉換為 PyTorch 張量\n",
    "    predictions = torch.from_numpy(np.array(basket_predictions, dtype=np.float32))\n",
    "    num_users = len(basket_targets)\n",
    "    ndcg_at_k_eval = dict()\n",
    "    \n",
    "    ndcg_sum = 0.0\n",
    "    for i in range(num_users):\n",
    "        # 將用戶 i 的真實標籤轉換為 PyTorch 張量\n",
    "        labels = torch.from_numpy(np.array(basket_targets[i], dtype=np.int64))\n",
    "        # 計算用戶 i 在預測機率矩陣中機率最高的 K 個項目的索引=標籤\n",
    "        top_k_item_labels = torch.topk(basket_predictions[i], size_predictions[i])[1]\n",
    "        # 計算 DCG@K\n",
    "        dcg_at_k = torch.sum(torch.nan_to_num(torch.div(1.0, torch.log2(torch.arange(size_predictions[i], dtype=torch.float32) +2))) * (torch.eq(top_k_item_labels, labels.unsqueeze(1)).to(torch.float32) ))\n",
    "        # 計算 IDCG@K\n",
    "        idcg_at_k = torch.sum(torch.div(1.0, torch.log2(torch.arange(len(labels), dtype=torch.float32) + 2)))\n",
    "        # 計算 NDCG@K * Penalty weight\n",
    "        if torch.eq(idcg_at_k, 0):\n",
    "            ndcg_at_k = idcg_at_k\n",
    "        else:\n",
    "            ndcg_at_k = (dcg_at_k / idcg_at_k) * (size_targets[i] / (size_targets[i] + abs(size_targets[i] - size_predictions[i])))\n",
    "        ndcg_sum += ndcg_at_k.item()\n",
    "    #　計算平均　NDCG@K 分數\n",
    "    ndcg_at_k = ndcg_sum / float(num_users)\n",
    "    key = \"{}\".format(\"NDCG\")\n",
    "    ndcg_at_k_eval[key] = ndcg_at_k\n",
    "\n",
    "    return ndcg_at_k_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0427fec7",
   "metadata": {},
   "source": [
    "# MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24ed1c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mae(size_predictions, size_targets):\n",
    "    sum = 0\n",
    "    num_users = len(size_targets)\n",
    "    mae_eval = dict()\n",
    "    for i in range(num_users):\n",
    "        sum += abs(size_predictions[i] - (size_targets[i]).item())\n",
    "    key = \"{}\".format(\"MAE\")\n",
    "    mae_eval[key] = sum / num_users\n",
    "    return mae_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67977dc5",
   "metadata": {},
   "source": [
    "# 訓練&測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90ea96e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練模型\n",
    "def train_model():\n",
    "    my_model.train()\n",
    "    loss_list = []\n",
    "    \n",
    "    for batch_idx, (userID, basket_input, basket_label, size_input, size_label) in enumerate(tqdm(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        basket_output, size_output = my_model(basket_input, size_input)\n",
    "        # 計算損失\n",
    "        loss = ALPHA * mean_square_error(size_output, size_label) + (1 - ALPHA) * cross_entropy_loss(basket_output, basket_label)\n",
    "        loss_list.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (batch_idx%100 == 0) or (batch_idx == len(train_dataloader)-1):\n",
    "            precentage = (100 * batch_idx/len(train_dataloader))\n",
    "            print(f\"Epoch {epoch}: {precentage:.0f}%, loss: {loss.item():.6f}\")\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            basket_output = torch.from_numpy(np.array(basket_output.cpu(), dtype=np.float32))\n",
    "            size_output = np.round(np.squeeze(np.array([_.cpu() for _ in size_output], dtype=np.float32))).astype(int).tolist()\n",
    "            if batch_idx == 0:\n",
    "                basket_outputs = basket_output\n",
    "                basket_labels = basket_label\n",
    "                size_outputs = size_output\n",
    "                size_labels = size_label\n",
    "            else:\n",
    "                basket_outputs = torch.cat( (basket_outputs, basket_output ),-2 )\n",
    "                basket_labels = basket_labels + basket_label\n",
    "                size_outputs = size_outputs + size_output\n",
    "                size_labels = size_labels + size_label\n",
    "                \n",
    "    with torch.no_grad():\n",
    "        evaluations = calculate_f1_score_at_k(basket_outputs, basket_labels, size_outputs) \n",
    "        res_str = '(' + format_metric(evaluations) + ')'\n",
    "        print(f\"                      {res_str}\\n\")\n",
    "\n",
    "        evaluations = calculate_ndcg_at_k(basket_outputs, basket_labels, size_outputs, size_labels) \n",
    "        res_str = '(' + format_metric(evaluations) + ')'\n",
    "        print(f\"                      {res_str}\\n\")\n",
    "\n",
    "        evaluations = calculate_mae(size_outputs, size_labels)\n",
    "        res_str = '(' + format_metric(evaluations) + ')'\n",
    "        print(f\"                      {res_str}\\n\")\n",
    "        \n",
    "    return torch.mean(torch.tensor(loss_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a21f208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 驗證模型\n",
    "def evaluate_model():\n",
    "    my_model.eval()\n",
    "    loss_list = []\n",
    "    for batch_idx, (userID, basket_input, basket_label, size_input, size_label) in enumerate(tqdm(valid_dataloader)):\n",
    "        basket_output, size_output = my_model(basket_input, size_input)\n",
    "        # 計算損失\n",
    "        loss = ALPHA * mean_square_error(size_output, size_label) + (1 - ALPHA) * cross_entropy_loss(basket_output, basket_label)\n",
    "        loss_list.append(loss.item())\n",
    "        with torch.no_grad():\n",
    "            basket_output = torch.from_numpy(np.array(basket_output.cpu(), dtype=np.float32))\n",
    "            size_output = np.round(np.squeeze(np.array([_.cpu() for _ in size_output], dtype=np.float32))).astype(int).tolist()\n",
    "            if batch_idx == 0:\n",
    "                basket_outputs = basket_output\n",
    "                basket_labels = basket_label\n",
    "                size_outputs = size_output\n",
    "                size_labels = size_label\n",
    "            else:\n",
    "                basket_outputs = torch.cat( (basket_outputs, basket_output ),-2 )\n",
    "                basket_labels = basket_labels + basket_label\n",
    "                size_outputs = size_outputs + size_output\n",
    "                size_labels = size_labels + size_label\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        evaluations = calculate_f1_score_at_k(basket_outputs, basket_labels, size_outputs) \n",
    "        res_str = '(' + format_metric(evaluations) + ')'\n",
    "        print(f\"                      {res_str}\\n\")\n",
    "\n",
    "        evaluations = calculate_ndcg_at_k(basket_outputs, basket_labels, size_outputs, size_labels) \n",
    "        res_str = '(' + format_metric(evaluations) + ')'\n",
    "        print(f\"                      {res_str}\\n\")\n",
    "\n",
    "        evaluations = calculate_mae(size_outputs, size_labels)\n",
    "        res_str = '(' + format_metric(evaluations) + ')'\n",
    "        print(f\"                      {res_str}\\n\")\n",
    "        \n",
    "    return torch.mean(torch.tensor(loss_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84ebc77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試模型\n",
    "def test_model():\n",
    "    my_model.eval()\n",
    "    loss_list = []\n",
    "    for batch_idx, (userID, basket_input, basket_label, size_input, size_label) in enumerate(tqdm(test_dataloader)):\n",
    "        basket_output, size_output = my_model(basket_input, size_input)\n",
    "        # 計算損失\n",
    "        loss = ALPHA * mean_square_error(size_output, size_label) + (1 - ALPHA) * cross_entropy_loss(basket_output, basket_label)\n",
    "        loss_list.append(loss.item())\n",
    "        with torch.no_grad():\n",
    "            basket_output = torch.from_numpy(np.array(basket_output.cpu(), dtype=np.float32))\n",
    "            size_output = np.round(np.squeeze(np.array([_.cpu() for _ in size_output], dtype=np.float32))).astype(int).tolist()\n",
    "            if batch_idx == 0:\n",
    "                basket_outputs = basket_output\n",
    "                basket_labels = basket_label\n",
    "                size_outputs = size_output\n",
    "                size_labels = size_label\n",
    "            else:\n",
    "                basket_outputs = torch.cat( (basket_outputs, basket_output ),-2 )\n",
    "                basket_labels = basket_labels + basket_label\n",
    "                size_outputs = size_outputs + size_output\n",
    "                size_labels = size_labels + size_label\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        f1_evaluations = calculate_f1_score_at_k(basket_outputs, basket_labels, size_outputs) \n",
    "        f1_list = [f1_evaluations]\n",
    "        res_str = '(' + format_metric(f1_evaluations) + ')'\n",
    "        print(f\"                      {res_str}\\n\")\n",
    "        \n",
    "        ndcg_evaluations = calculate_ndcg_at_k(basket_outputs, basket_labels, size_outputs, size_labels) \n",
    "        ndcg_list = [ndcg_evaluations]\n",
    "        res_str = '(' + format_metric(ndcg_evaluations) + ')'\n",
    "        print(f\"                      {res_str}\\n\")\n",
    "        \n",
    "        mae_evaluations = calculate_mae(size_outputs, size_labels)\n",
    "        mae_list = [mae_evaluations]\n",
    "        res_str = '(' + format_metric(mae_evaluations) + ')'\n",
    "        print(f\"                      {res_str}\\n\")\n",
    "        \n",
    "    return torch.mean(torch.tensor(loss_list)), f1_list, ndcg_list, mae_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412698b2",
   "metadata": {},
   "source": [
    "# 完整模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bfd2fd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_count= 15764\n",
      "tensor([1.7128e-03, 1.1418e-03, 2.4169e-02,  ..., 6.3436e-05, 6.3436e-05,\n",
      "        6.3436e-05], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 項目總數\n",
    "items_count = confidences_array.shape[0]\n",
    "print(\"items_count=\", items_count)\n",
    "# 項目出現次數\n",
    "items_freq = Counter(dataset[\"NEW_ITEM_ID\"])\n",
    "# 計算每個項目出現的比例: items_frq/items_count\n",
    "item_weight = torch.tensor(np.array(list(items_freq.values()))/items_count).to(device)\n",
    "# 按照new_item_id順序排列\n",
    "print(item_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3508db",
   "metadata": {},
   "source": [
    "# 加上信賴度矩陣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90d93488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0741, 0.0741,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.1111,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "       device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 信賴度矩陣\n",
    "confidences_array = torch.tensor(confidences_array, dtype=torch.float64).to(device)\n",
    "confidences_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c5a0e563",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel01(nn.Module):\n",
    "    def __init__(self, embed_dim, model_dim, hidden_dim, items_count):\n",
    "        super(MyModel01, self).__init__()\n",
    "        self.model_dim = model_dim\n",
    "        self.embedding = nn.Embedding.from_pretrained(weights, freeze=False)\n",
    "        self.embedding.requires_grad=True\n",
    "        self.basket_embed = SelfAttention(embed_dim=embed_dim, model_dim=model_dim)\n",
    "        self.size_embed = LSTM(1,1)\n",
    "        self.model_encoder = TransformerEncoder(d_model=model_dim, num_heads=NUM_HEAD, num_layers=NUM_LAYER)\n",
    "        # 嵌入維度、隱藏層維度、總項目數量\n",
    "        self.basket_mlp = MLPforItem(model_dim, hidden_dim, items_count)\n",
    "        self.size_mlp = MLPforSize(model_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, basket_input, size_input):\n",
    "        basket_list, size_list, attention_mask, k_list = [], [], [], []\n",
    "        output_list = []\n",
    "        \n",
    "        # 為每個用戶的購物籃加上 padding跟 mask\n",
    "        for user in basket_input:\n",
    "            # 將購物籃項目 ID 轉換為嵌入向量\n",
    "            batch_features = [ self.embedding(torch.tensor(cart).to(device)) for cart in user ]\n",
    "            # 進行 padding\n",
    "            batch_features = rnn_utils.pad_sequence(batch_features, batch_first=True, padding_value=0)\n",
    "            # 購物籃中項目的遮罩\n",
    "            mask = ~batch_features.sum(dim=-1).ne(0)\n",
    "            basket_list.append(batch_features)\n",
    "            attention_mask.append(mask)\n",
    "        \n",
    "        # 預測size_tensor\n",
    "        sizes_input = [torch.tensor(size).to(device) for size in size_input]\n",
    "        tmp_tensor = torch.zeros(max_cart_count)\n",
    "        size_list.append(tmp_tensor)\n",
    "        for size in sizes_input:\n",
    "            size_list.append(size)\n",
    "        size_list = rnn_utils.pad_sequence(size_list, batch_first=True, padding_value=0)[1:]\n",
    "            \n",
    "        # 進入自注意力，輸出形狀(BATCH_SIZE, basket_size, embed_dim)\n",
    "        basket_embedding_list = []\n",
    "        for i, user_inputs in enumerate(basket_list):\n",
    "            basket_embedding_list.append(self.basket_embed(user_inputs, attention_mask[i]))\n",
    "        \n",
    "        # size通過lstm進行編碼\n",
    "        for i, user_inputs in enumerate(size_list):\n",
    "            k_list.append(self.size_embed(torch.tensor([[float(_)] for _ in size_list[i]]).to(device)))\n",
    "        \n",
    "        # 進行購物籃的 padding\n",
    "        input_seq = rnn_utils.pad_sequence(basket_embedding_list, batch_first=True, padding_value=0)\n",
    "        \n",
    "        # 進入Transformer\n",
    "        basket_embed = self.model_encoder(input_seq.to(device))\n",
    "        \n",
    "        B_s_list = []\n",
    "        \n",
    "        for i, b in enumerate(basket_embed):\n",
    "            basket_size = len(attention_mask[i])\n",
    "            B_s = b[basket_size-1]  # 取得最後一個購物籃向量\n",
    "            B_s_list.append(B_s)\n",
    "        \n",
    "        # 進入basket MLP層\n",
    "        p = self.basket_mlp(torch.stack(B_s_list, dim=0))\n",
    "        pc = (self.relu(p.to(torch.float64))+1e-8) @ confidences_array\n",
    "        pw = torch.mul( p, item_weight )\n",
    "        p_ = torch.mul(BETA, torch.add(pc,pw)) + torch.mul(1-BETA, p.to(torch.float64))\n",
    "        y = p_\n",
    "        \n",
    "        # 進入size MLP層\n",
    "        k = self.size_mlp(torch.stack(k_list, dim=0))\n",
    "        \n",
    "        return y, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5922dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel01(\n",
       "  (embedding): Embedding(15764, 32)\n",
       "  (basket_embed): SelfAttention(\n",
       "    (query_matrix): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (key_matrix): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (value_matrix): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (multihead_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (size_embed): LSTM(\n",
       "    (lstm): LSTM(1, 16, num_layers=2)\n",
       "    (hiddenlayer1): Linear(in_features=1152, out_features=512, bias=True)\n",
       "    (hiddenlayer2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (hiddenlayer3): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (hiddenlayer4): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (embed): Linear(in_features=128, out_features=32, bias=True)\n",
       "    (leakyrelu): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (model_encoder): TransformerEncoder(\n",
       "    (pe): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (transformer): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (basket_mlp): MLPforItem(\n",
       "    (hidden): Linear(in_features=32, out_features=128, bias=True)\n",
       "    (norm): BatchNorm1d(128, eps=1e-05, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "    (output): Linear(in_features=128, out_features=15764, bias=True)\n",
       "  )\n",
       "  (size_mlp): MLPforSize(\n",
       "    (predict): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (leakyrelu): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = MyModel01(embed_dim=EMBEDDING_DIMENSION, model_dim=MODEL_DIMENSION, hidden_dim=HIDDEN_DIMENSION, items_count=items_count).to(device)\n",
    "optimizer = torch.optim.Adam(my_model.parameters(), lr=LEARNING_RATE)\n",
    "my_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ea8f62",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1065 [00:00<11:17,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 0%, loss: 151.072876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 101/1065 [00:26<04:06,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 9%, loss: 16.322041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 201/1065 [00:54<04:35,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 19%, loss: 28.844355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 301/1065 [01:23<03:41,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 28%, loss: 44.661697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 401/1065 [01:53<03:30,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 38%, loss: 10.057695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 501/1065 [02:23<03:06,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 47%, loss: 19.810877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 601/1065 [02:55<02:33,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 56%, loss: 42.338947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 701/1065 [03:29<02:02,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 66%, loss: 27.594660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 801/1065 [04:02<01:29,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 75%, loss: 47.710537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 901/1065 [04:37<00:58,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 85%, loss: 15.116541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1001/1065 [05:12<00:23,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 94%, loss: 29.204096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1065/1065 [05:36<00:00,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%, loss: 5.437896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      (F1-score: 0.0063)\n",
      "\n",
      "                      (NDCG: 0.0060)\n",
      "\n",
      "                      (MAE: 4.4901)\n",
      "\n",
      "train_loss= tensor(35.1452)\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:22<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      (F1-score: 0.0001)\n",
      "\n",
      "                      (NDCG: 0.0001)\n",
      "\n",
      "                      (MAE: 4.3205)\n",
      "\n",
      "val_loss= tensor(30.8904)\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:21<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      (F1-score: 0.0002)\n",
      "\n",
      "                      (NDCG: 0.0001)\n",
      "\n",
      "                      (MAE: 4.2923)\n",
      "\n",
      "--------------------\n",
      "[[1, {'F1-score': 0.0001709677197496979}, {'NDCG': 7.514301529924448e-05}, {'MAE': 4.292293233082707}, 29.84501838684082]]\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1065 [00:00<04:13,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 0%, loss: 25.580425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 101/1065 [00:27<04:15,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 9%, loss: 31.514866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 201/1065 [00:54<03:54,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 19%, loss: 36.681316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 301/1065 [01:23<03:25,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 28%, loss: 4.043067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 401/1065 [01:51<03:12,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 38%, loss: 33.491985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 501/1065 [02:22<02:46,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 47%, loss: 11.884916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 601/1065 [02:53<02:29,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 56%, loss: 3.917925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 701/1065 [03:26<02:00,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 66%, loss: 41.285542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 801/1065 [04:01<01:30,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 75%, loss: 15.355593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 901/1065 [04:36<00:56,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 85%, loss: 10.663137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1001/1065 [05:12<00:24,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 94%, loss: 25.281384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1065/1065 [05:35<00:00,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%, loss: 9.244298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      (F1-score: 0.0001)\n",
      "\n",
      "                      (NDCG: 0.0000)\n",
      "\n",
      "                      (MAE: 4.0998)\n",
      "\n",
      "train_loss= tensor(29.5839)\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:22<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      (F1-score: 0.0000)\n",
      "\n",
      "                      (NDCG: 0.0000)\n",
      "\n",
      "                      (MAE: 4.0611)\n",
      "\n",
      "val_loss= tensor(31.2898)\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:21<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      (F1-score: 0.0001)\n",
      "\n",
      "                      (NDCG: 0.0000)\n",
      "\n",
      "                      (MAE: 3.9098)\n",
      "\n",
      "--------------------\n",
      "[[1, {'F1-score': 0.0001709677197496979}, {'NDCG': 7.514301529924448e-05}, {'MAE': 4.292293233082707}, 29.84501838684082], [2, {'F1-score': 6.885345231209893e-05}, {'NDCG': 3.09213222165529e-05}, {'MAE': 3.9097744360902253}, 29.40765953063965]]\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1065 [00:00<05:01,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 0%, loss: 53.626190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 101/1065 [00:26<04:21,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 9%, loss: 39.499893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 201/1065 [00:54<03:50,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 19%, loss: 8.605682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 301/1065 [01:22<03:29,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 28%, loss: 217.611984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 401/1065 [01:51<03:07,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 38%, loss: 21.665529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 501/1065 [02:22<03:07,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 47%, loss: 6.352293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 601/1065 [02:53<02:34,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 56%, loss: 9.914840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 701/1065 [03:26<02:08,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 66%, loss: 11.068206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 801/1065 [04:00<01:25,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 75%, loss: 24.209066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 901/1065 [04:36<00:57,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 85%, loss: 11.924843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1001/1065 [05:11<00:22,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 94%, loss: 63.701687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1065/1065 [05:35<00:00,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%, loss: 39.467876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      (F1-score: 0.0001)\n",
      "\n",
      "                      (NDCG: 0.0000)\n",
      "\n",
      "                      (MAE: 4.0772)\n",
      "\n",
      "train_loss= tensor(29.1440)\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:22<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      (F1-score: 0.0002)\n",
      "\n",
      "                      (NDCG: 0.0001)\n",
      "\n",
      "                      (MAE: 4.1936)\n",
      "\n",
      "val_loss= tensor(36.2078)\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:21<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      (F1-score: 0.0005)\n",
      "\n",
      "                      (NDCG: 0.0002)\n",
      "\n",
      "                      (MAE: 3.9408)\n",
      "\n",
      "--------------------\n",
      "[[1, {'F1-score': 0.0001709677197496979}, {'NDCG': 7.514301529924448e-05}, {'MAE': 4.292293233082707}, 29.84501838684082], [2, {'F1-score': 6.885345231209893e-05}, {'NDCG': 3.09213222165529e-05}, {'MAE': 3.9097744360902253}, 29.40765953063965], [3, {'F1-score': 0.0005252089540396515}, {'NDCG': 0.00021626549786923075}, {'MAE': 3.9407894736842106}, 33.605140686035156]]\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1065 [00:00<05:17,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 0%, loss: 49.989120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 101/1065 [00:28<04:20,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 9%, loss: 7.396740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 201/1065 [00:55<03:53,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 19%, loss: 157.367935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 301/1065 [01:24<03:48,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 28%, loss: 33.360958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 401/1065 [01:52<03:12,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 38%, loss: 10.268783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 501/1065 [02:23<02:51,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 47%, loss: 9.822732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 601/1065 [02:54<02:44,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 56%, loss: 11.763803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 701/1065 [03:28<02:08,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 66%, loss: 4.099924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 801/1065 [04:02<01:40,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 75%, loss: 27.823591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 901/1065 [04:37<00:58,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 85%, loss: 12.949684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1001/1065 [05:13<00:23,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 94%, loss: 94.539192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1065/1065 [05:36<00:00,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%, loss: 27.669836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      (F1-score: 0.0099)\n",
      "\n",
      "                      (NDCG: 0.0077)\n",
      "\n",
      "                      (MAE: 4.0593)\n",
      "\n",
      "train_loss= tensor(28.8449)\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:22<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      (F1-score: 0.0141)\n",
      "\n",
      "                      (NDCG: 0.0161)\n",
      "\n",
      "                      (MAE: 4.2397)\n",
      "\n",
      "val_loss= tensor(29.7709)\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:21<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      (F1-score: 0.0160)\n",
      "\n",
      "                      (NDCG: 0.0178)\n",
      "\n",
      "                      (MAE: 4.2133)\n",
      "\n",
      "--------------------\n",
      "[[1, {'F1-score': 0.0001709677197496979}, {'NDCG': 7.514301529924448e-05}, {'MAE': 4.292293233082707}, 29.84501838684082], [2, {'F1-score': 6.885345231209893e-05}, {'NDCG': 3.09213222165529e-05}, {'MAE': 3.9097744360902253}, 29.40765953063965], [3, {'F1-score': 0.0005252089540396515}, {'NDCG': 0.00021626549786923075}, {'MAE': 3.9407894736842106}, 33.605140686035156], [4, {'F1-score': 0.015962576029807638}, {'NDCG': 0.017818498838328777}, {'MAE': 4.213345864661654}, 28.84568977355957]]\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1065 [00:00<04:27,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 0%, loss: 76.776505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 101/1065 [00:27<04:20,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 9%, loss: 37.431190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 201/1065 [00:55<03:57,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 19%, loss: 19.042934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 301/1065 [01:23<03:30,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 28%, loss: 36.144855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 401/1065 [01:52<03:26,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 38%, loss: 42.307449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 501/1065 [02:23<03:03,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 47%, loss: 26.860182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 601/1065 [02:55<02:19,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 56%, loss: 19.365690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 701/1065 [03:27<01:58,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 66%, loss: 10.431344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 801/1065 [04:01<01:26,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 75%, loss: 9.059081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 901/1065 [04:36<00:54,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 85%, loss: 4.468736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1001/1065 [05:12<00:22,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 94%, loss: 4.706221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1065/1065 [05:35<00:00,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%, loss: 39.122250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      (F1-score: 0.0186)\n",
      "\n",
      "                      (NDCG: 0.0226)\n",
      "\n",
      "                      (MAE: 4.0507)\n",
      "\n",
      "train_loss= tensor(28.6441)\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:22<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      (F1-score: 0.0204)\n",
      "\n",
      "                      (NDCG: 0.0256)\n",
      "\n",
      "                      (MAE: 3.9934)\n",
      "\n",
      "val_loss= tensor(31.8237)\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:21<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      (F1-score: 0.0237)\n",
      "\n",
      "                      (NDCG: 0.0303)\n",
      "\n",
      "                      (MAE: 3.8205)\n",
      "\n",
      "--------------------\n",
      "[[1, {'F1-score': 0.0001709677197496979}, {'NDCG': 7.514301529924448e-05}, {'MAE': 4.292293233082707}, 29.84501838684082], [2, {'F1-score': 6.885345231209893e-05}, {'NDCG': 3.09213222165529e-05}, {'MAE': 3.9097744360902253}, 29.40765953063965], [3, {'F1-score': 0.0005252089540396515}, {'NDCG': 0.00021626549786923075}, {'MAE': 3.9407894736842106}, 33.605140686035156], [4, {'F1-score': 0.015962576029807638}, {'NDCG': 0.017818498838328777}, {'MAE': 4.213345864661654}, 28.84568977355957], [5, {'F1-score': 0.023711579980802776}, {'NDCG': 0.0302586423555263}, {'MAE': 3.8204887218045114}, 30.032276153564453]]\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1065 [00:00<04:19,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 0%, loss: 33.700836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 101/1065 [00:26<04:19,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 9%, loss: 33.032097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 201/1065 [00:54<03:49,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 19%, loss: 16.543489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 301/1065 [01:22<03:20,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 28%, loss: 30.251989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 401/1065 [01:51<03:15,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 38%, loss: 51.616978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 501/1065 [02:22<02:47,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 47%, loss: 39.447792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 601/1065 [02:54<02:31,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 56%, loss: 31.451775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 701/1065 [03:26<01:54,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 66%, loss: 21.758905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 801/1065 [04:00<01:30,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 75%, loss: 23.353371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 901/1065 [04:35<00:56,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 85%, loss: 4.674962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1001/1065 [05:12<00:25,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 94%, loss: 164.875702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1065/1065 [05:36<00:00,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%, loss: 20.012758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      (F1-score: 0.0265)\n",
      "\n",
      "                      (NDCG: 0.0307)\n",
      "\n",
      "                      (MAE: 4.0369)\n",
      "\n",
      "train_loss= tensor(28.5653)\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:22<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      (F1-score: 0.0297)\n",
      "\n",
      "                      (NDCG: 0.0324)\n",
      "\n",
      "                      (MAE: 3.9586)\n",
      "\n",
      "val_loss= tensor(30.2516)\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:21<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      (F1-score: 0.0379)\n",
      "\n",
      "                      (NDCG: 0.0400)\n",
      "\n",
      "                      (MAE: 3.8393)\n",
      "\n",
      "--------------------\n",
      "[[1, {'F1-score': 0.0001709677197496979}, {'NDCG': 7.514301529924448e-05}, {'MAE': 4.292293233082707}, 29.84501838684082], [2, {'F1-score': 6.885345231209893e-05}, {'NDCG': 3.09213222165529e-05}, {'MAE': 3.9097744360902253}, 29.40765953063965], [3, {'F1-score': 0.0005252089540396515}, {'NDCG': 0.00021626549786923075}, {'MAE': 3.9407894736842106}, 33.605140686035156], [4, {'F1-score': 0.015962576029807638}, {'NDCG': 0.017818498838328777}, {'MAE': 4.213345864661654}, 28.84568977355957], [5, {'F1-score': 0.023711579980802776}, {'NDCG': 0.0302586423555263}, {'MAE': 3.8204887218045114}, 30.032276153564453], [6, {'F1-score': 0.03794659612273717}, {'NDCG': 0.040000335461306}, {'MAE': 3.8392857142857144}, 28.908143997192383]]\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1065 [00:00<04:43,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 0%, loss: 3.442751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 101/1065 [00:26<04:33,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 9%, loss: 12.663728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 201/1065 [00:54<04:02,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 19%, loss: 15.431534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 301/1065 [01:23<03:29,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 28%, loss: 24.960506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 401/1065 [01:53<03:16,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 38%, loss: 70.201157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 501/1065 [02:24<02:53,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 47%, loss: 46.009628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 601/1065 [02:56<02:24,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 56%, loss: 23.644382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 701/1065 [03:28<01:56,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 66%, loss: 28.847084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 801/1065 [04:02<01:30,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 75%, loss: 23.054811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 901/1065 [04:37<01:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 85%, loss: 9.549104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1001/1065 [05:12<00:23,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 94%, loss: 11.043426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1065/1065 [05:36<00:00,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%, loss: 23.613634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      (F1-score: 0.0402)\n",
      "\n",
      "                      (NDCG: 0.0402)\n",
      "\n",
      "                      (MAE: 4.0273)\n",
      "\n",
      "train_loss= tensor(28.2821)\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:22<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      (F1-score: 0.0395)\n",
      "\n",
      "                      (NDCG: 0.0387)\n",
      "\n",
      "                      (MAE: 3.9821)\n",
      "\n",
      "val_loss= tensor(31.4813)\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:21<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      (F1-score: 0.0477)\n",
      "\n",
      "                      (NDCG: 0.0463)\n",
      "\n",
      "                      (MAE: 3.8111)\n",
      "\n",
      "--------------------\n",
      "[[1, {'F1-score': 0.0001709677197496979}, {'NDCG': 7.514301529924448e-05}, {'MAE': 4.292293233082707}, 29.84501838684082], [2, {'F1-score': 6.885345231209893e-05}, {'NDCG': 3.09213222165529e-05}, {'MAE': 3.9097744360902253}, 29.40765953063965], [3, {'F1-score': 0.0005252089540396515}, {'NDCG': 0.00021626549786923075}, {'MAE': 3.9407894736842106}, 33.605140686035156], [4, {'F1-score': 0.015962576029807638}, {'NDCG': 0.017818498838328777}, {'MAE': 4.213345864661654}, 28.84568977355957], [5, {'F1-score': 0.023711579980802776}, {'NDCG': 0.0302586423555263}, {'MAE': 3.8204887218045114}, 30.032276153564453], [6, {'F1-score': 0.03794659612273717}, {'NDCG': 0.040000335461306}, {'MAE': 3.8392857142857144}, 28.908143997192383], [7, {'F1-score': 0.04768036243929811}, {'NDCG': 0.046260364893718826}, {'MAE': 3.81109022556391}, 29.836551666259766]]\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1065 [00:00<04:26,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 0%, loss: 48.338081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 101/1065 [00:27<04:07,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 9%, loss: 17.515272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 201/1065 [00:54<04:01,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 19%, loss: 22.662556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 301/1065 [01:23<03:31,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 28%, loss: 7.546237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 401/1065 [01:52<03:06,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 38%, loss: 16.328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 501/1065 [02:23<02:56,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 47%, loss: 13.658923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 601/1065 [02:55<02:29,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 56%, loss: 17.617048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 701/1065 [03:27<01:59,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 66%, loss: 6.366136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 801/1065 [04:01<01:29,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 75%, loss: 7.864896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 901/1065 [04:36<00:58,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 85%, loss: 14.207162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1001/1065 [05:13<00:24,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 94%, loss: 23.487064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1065/1065 [05:36<00:00,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%, loss: 17.659735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      (F1-score: 0.0453)\n",
      "\n",
      "                      (NDCG: 0.0432)\n",
      "\n",
      "                      (MAE: 4.0208)\n",
      "\n",
      "train_loss= tensor(28.3216)\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:22<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      (F1-score: 0.0404)\n",
      "\n",
      "                      (NDCG: 0.0391)\n",
      "\n",
      "                      (MAE: 4.0545)\n",
      "\n",
      "val_loss= tensor(29.2132)\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:21<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      (F1-score: 0.0488)\n",
      "\n",
      "                      (NDCG: 0.0466)\n",
      "\n",
      "                      (MAE: 3.9577)\n",
      "\n",
      "--------------------\n",
      "[[1, {'F1-score': 0.0001709677197496979}, {'NDCG': 7.514301529924448e-05}, {'MAE': 4.292293233082707}, 29.84501838684082], [2, {'F1-score': 6.885345231209893e-05}, {'NDCG': 3.09213222165529e-05}, {'MAE': 3.9097744360902253}, 29.40765953063965], [3, {'F1-score': 0.0005252089540396515}, {'NDCG': 0.00021626549786923075}, {'MAE': 3.9407894736842106}, 33.605140686035156], [4, {'F1-score': 0.015962576029807638}, {'NDCG': 0.017818498838328777}, {'MAE': 4.213345864661654}, 28.84568977355957], [5, {'F1-score': 0.023711579980802776}, {'NDCG': 0.0302586423555263}, {'MAE': 3.8204887218045114}, 30.032276153564453], [6, {'F1-score': 0.03794659612273717}, {'NDCG': 0.040000335461306}, {'MAE': 3.8392857142857144}, 28.908143997192383], [7, {'F1-score': 0.04768036243929811}, {'NDCG': 0.046260364893718826}, {'MAE': 3.81109022556391}, 29.836551666259766], [8, {'F1-score': 0.04882115029006257}, {'NDCG': 0.04662863852428202}, {'MAE': 3.957706766917293}, 28.035444259643555]]\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1065 [00:00<04:15,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 0%, loss: 12.730721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 101/1065 [00:27<04:15,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 9%, loss: 10.022324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 201/1065 [00:55<03:59,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 19%, loss: 14.281415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 301/1065 [01:23<03:33,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 28%, loss: 7.393651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 401/1065 [01:53<03:15,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 38%, loss: 36.068092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 406/1065 [01:55<03:34,  3.07it/s]"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss = train_model()\n",
    "    print(\"train_loss=\", train_loss)\n",
    "    print(\"-\"*20)\n",
    "    val_loss = evaluate_model()\n",
    "    print(\"val_loss=\", val_loss)\n",
    "    print(\"-\"*20)\n",
    "    test_loss, f1_list, ndcg_list, mae_list = test_model()\n",
    "    print(\"-\"*20)\n",
    "    result = [epoch] + f1_list + ndcg_list + mae_list + [test_loss.item()]\n",
    "    results.append(result)\n",
    "    print(results)\n",
    "    print(\"-\"*89)\n",
    "    \n",
    "    collected = gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "record_df = pd.DataFrame(results, columns=[\"Epoch\", \"F1-score\", \"NDCG\", \"MAE\", \"Loss\"])\n",
    "\n",
    "record_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
