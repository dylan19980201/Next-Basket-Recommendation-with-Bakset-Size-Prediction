{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a246ddd9",
   "metadata": {},
   "source": [
    "# 下載套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72209793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import nn, matmul, softmax\n",
    "from torch.nn.init import xavier_uniform_\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "import gzip \n",
    "import gc\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3db86c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32d7025",
   "metadata": {},
   "source": [
    "# 參數設置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6da217e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超參數\n",
    "EPOCHS = 25\n",
    "LEARNING_RATE = 0.0001 \n",
    "BATCH_SIZE = 8\n",
    "BETA = 0.5\n",
    "ALPHA = 0.3\n",
    "EMBEDDING_DIMENSION = 32                      # 嵌入維度\n",
    "MODEL_DIMENSION = EMBEDDING_DIMENSION         # 模型維度\n",
    "HIDDEN_DIMENSION = 128                        # NLP 隱藏層維度\n",
    "NUM_HEAD = 4\n",
    "NUM_LAYER = 4\n",
    "\n",
    "isI2V = 1        #1:使用Item2Vec     #0:不使用Item2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4283cbc8",
   "metadata": {},
   "source": [
    "# 匯入檔案\n",
    "- item2Vec_TaFeng.32d.model\n",
    "- TaFeng_user_cart_itemid_list.gz\n",
    "- Ta_feng_clean.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32520298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15764, 32])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load word2Vec pre_train model\n",
    "model_filename = f\"../preprocessing-data/item2vec_models/item2vec_TaFeng.{EMBEDDING_DIMENSION}d.model\"\n",
    "## TaFeng\n",
    "with open(model_filename, \"rb\") as fp:\n",
    "    model = pickle.load(fp)\n",
    "weights = torch.FloatTensor(model.wv.vectors)\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbe80d00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1113,\n",
       "  array([0., 1.]),\n",
       "  [[0, 1, 2], [3, 4, 5, 6, 7, 8], [9, 10, 11, 12, 13, 14, 15]],\n",
       "  [3, 6, 7]),\n",
       " (5241,\n",
       "  array([0.        , 0.70967742, 1.        ]),\n",
       "  [[16, 17, 18, 19, 20, 21],\n",
       "   [22, 23, 24, 25, 26, 27, 28, 29, 30, 31],\n",
       "   [32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47],\n",
       "   [48, 49, 50, 51, 52]],\n",
       "  [6, 10, 16, 5])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TaFeng # TaFeng_user_cart_itemid_list # 用戶id, 購物籃時間差(不會使用到), 此用戶的購物籃串列(每個串列包含多筆項目)。\n",
    "with gzip.open(\"../preprocessing-data/TaFeng_user_cart_Itemid_list.gz\", \"rb\") as fp:\n",
    "    user_cart_itemid_list = pickle.load(fp)\n",
    "user_cart_itemid_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "361c43d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TaFeng confidences_Matrix\n",
    "with gzip.open(\"../preprocessing-data/confidences/TaFeng_confidences_array.gz\", \"rb\") as fp:\n",
    "    TaFeng_confidences_array = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b83d2fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUSTOMER_ID</th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>TRANSACTION_DT</th>\n",
       "      <th>CART_ID</th>\n",
       "      <th>NEW_ITEM_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1113</td>\n",
       "      <td>4902105011621</td>\n",
       "      <td>2000-11-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1113</td>\n",
       "      <td>7616100830794</td>\n",
       "      <td>2000-11-26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1113</td>\n",
       "      <td>4710892632017</td>\n",
       "      <td>2000-11-26</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1113</td>\n",
       "      <td>4710905340113</td>\n",
       "      <td>2000-11-27</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1113</td>\n",
       "      <td>4717362901277</td>\n",
       "      <td>2000-11-27</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533054</th>\n",
       "      <td>20002000</td>\n",
       "      <td>4710339772139</td>\n",
       "      <td>2001-01-20</td>\n",
       "      <td>62360</td>\n",
       "      <td>4546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533055</th>\n",
       "      <td>20002000</td>\n",
       "      <td>20513184</td>\n",
       "      <td>2001-01-20</td>\n",
       "      <td>62360</td>\n",
       "      <td>1351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533056</th>\n",
       "      <td>20002000</td>\n",
       "      <td>4714800731229</td>\n",
       "      <td>2001-01-20</td>\n",
       "      <td>62360</td>\n",
       "      <td>2946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533057</th>\n",
       "      <td>20002000</td>\n",
       "      <td>4714541091071</td>\n",
       "      <td>2001-01-20</td>\n",
       "      <td>62360</td>\n",
       "      <td>7382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533058</th>\n",
       "      <td>20002000</td>\n",
       "      <td>4710018008634</td>\n",
       "      <td>2001-01-20</td>\n",
       "      <td>62360</td>\n",
       "      <td>2629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>533059 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CUSTOMER_ID     PRODUCT_ID TRANSACTION_DT  CART_ID  NEW_ITEM_ID\n",
       "0              1113  4902105011621     2000-11-26        0            0\n",
       "1              1113  7616100830794     2000-11-26        0            1\n",
       "2              1113  4710892632017     2000-11-26        0            2\n",
       "3              1113  4710905340113     2000-11-27        1            3\n",
       "4              1113  4717362901277     2000-11-27        1            4\n",
       "...             ...            ...            ...      ...          ...\n",
       "533054     20002000  4710339772139     2001-01-20    62360         4546\n",
       "533055     20002000       20513184     2001-01-20    62360         1351\n",
       "533056     20002000  4714800731229     2001-01-20    62360         2946\n",
       "533057     20002000  4714541091071     2001-01-20    62360         7382\n",
       "533058     20002000  4710018008634     2001-01-20    62360         2629\n",
       "\n",
       "[533059 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ta Feng Dataset\n",
    "TaFeng = pd.read_csv(\"../cleaned_dataset/ta_feng_clean.csv\")\n",
    "\n",
    "# 最多購物籃數\n",
    "max_cart_count = TaFeng.groupby('CUSTOMER_ID')['CART_ID'].nunique().max()\n",
    "print(max_cart_count)\n",
    "\n",
    "TaFeng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0877d82",
   "metadata": {},
   "source": [
    "# 切分資料集\n",
    "- 分成輸入資料與標籤資料\n",
    "- 訓練集:驗證集:測試集 = 7:1:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73e9cf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7457\n",
      "1065\n",
      "2132\n"
     ]
    }
   ],
   "source": [
    "# 切分資料集\n",
    "train_set_size = int(len(user_cart_itemid_list) * 0.7)\n",
    "valid_set_size = int(len(user_cart_itemid_list) * 0.1)\n",
    "test_set_size = len(user_cart_itemid_list)-train_set_size-valid_set_size\n",
    "train_set, valid_set, test_set = random_split(user_cart_itemid_list, [train_set_size, valid_set_size, test_set_size])\n",
    "print(len(train_set))\n",
    "print(len(valid_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5edaa93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將切割好的資料集暫存起來\n",
    "\n",
    "# # 訓練集\n",
    "# filepath = \"../preprocessing-data/TaFeng_dataset/train_set.pkl\"\n",
    "# with open(filepath, \"wb\") as f:\n",
    "#     pickle.dump(train_set, f, pickle.HIGHEST_PROTOCOL)\n",
    "# # 驗證集\n",
    "# filepath = \"../preprocessing-data/TaFeng_dataset/valid_set.pkl\"\n",
    "# with open(filepath, \"wb\") as f:\n",
    "#     pickle.dump(valid_set, f, pickle.HIGHEST_PROTOCOL)\n",
    "# # 測試集\n",
    "# filepath = \"../preprocessing-data/TaFeng_dataset/test_set.pkl\"\n",
    "# with open(filepath, \"wb\") as f:\n",
    "#     pickle.dump(test_set, f, pickle.HIGHEST_PROTOCCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b203d0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取之前暫存的資料集\n",
    "\n",
    "# # 載入訓練、驗證、測試集\n",
    "# with open(\"../preprocessing-data/TaFeng_dataset/train_set.pkl\", \"rb\") as fp:\n",
    "#     train_set = pickle.load(fp)\n",
    "# with open(\"../preprocessing-data/TaFeng_dataset/valid_set.pkl\", \"rb\") as fp:\n",
    "#     valid_set = pickle.load(fp)\n",
    "# with open(\"../preprocessing-data/TaFeng_dataset/test_set.pkl\", \"rb\") as fp:\n",
    "#     test_set = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9585447",
   "metadata": {},
   "source": [
    "# Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a209539b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b348e2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義資料轉換函數(於collate_batch函式中使用)\n",
    "item_index_pipeline = lambda x:[[model.wv.key_to_index[j] for j in i]for i in x] # 取得購物籃中，項目的索引值(只有使用Item2Vec時會需要)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92fb3dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorDataset(Dataset):\n",
    "    # TensorDataset繼承Dataset, 重載__init__, __getitem__, __len__\n",
    "    # 實現將一組Tensor數據封裝成Tensor數據集\n",
    "    # 能夠通過index得到數據集的數據，能夠通過len，得到數據集大小\n",
    "    def __init__(self, data_tensor):\n",
    "        self.data_tensor = data_tensor\n",
    "    def __getitem__(self, index):\n",
    "        return self.data_tensor[index]\n",
    "    def __len__(self):\n",
    "        return len(self.data_tensor)\n",
    "\n",
    "def collate_batch(batch): # 輸出userID, input_list跟label(最後一個購物籃)\n",
    "    # 使用ID、時間差、訓練的購物籃項目、預測的購物籃項目\n",
    "    userID, input_list, label_list, input_size_list, label_size_list, offsets = [], [], [], [], [], [0]\n",
    "    for _user in batch:\n",
    "        userID.append(_user[0]) # userID\n",
    "        label_list.append(torch.tensor(_user[2][-1])) # 所有購物籃的項目ID串列中的最後一個購物籃項目ID\n",
    "        label_size_list.append(torch.tensor(_user[3][-1]))\n",
    "        \n",
    "        if isI2V == 0: # 不使用Item2Vec進行項目嵌入\n",
    "            train_list = _user[2][0:-1]\n",
    "        else: #　使用Item2Vec進行項目嵌入\n",
    "            train_list = item_index_pipeline(_user[2][0:-1])\n",
    "        input_size_list.append(_user[3][0:-1])\n",
    "        \n",
    "        input_list.append(train_list) # 所有購物籃的項目ID串列(除了最後一個購物籃)\n",
    "        offsets.append(len(train_list))\n",
    "    \n",
    "    return userID, input_list, label_list, input_size_list, label_size_list, offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f442f66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 轉成 Dataset\n",
    "split_train_ = TensorDataset(train_set)\n",
    "split_valid_ = TensorDataset(valid_set)\n",
    "split_test_ = TensorDataset(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54fe7bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader \n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch, drop_last=True)\n",
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch, drop_last=True)\n",
    "test_dataloader = DataLoader(split_test_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637657be",
   "metadata": {},
   "source": [
    "# Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a96171ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用nn.MultiheadAttention\n",
    "# 輸入一個用戶的一個購物籃，輸出購物籃嵌入\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, model_dim): #項目向量維度，輸出模型的維度\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.model_dim = model_dim\n",
    "        \n",
    "        # 初始化Q, K, V 矩陣\n",
    "        self.query_matrix = nn.Linear(embed_dim, model_dim)\n",
    "        xavier_uniform_(self.query_matrix.weight)\n",
    "        self.key_matrix = nn.Linear(embed_dim, model_dim)\n",
    "        xavier_uniform_(self.key_matrix.weight)\n",
    "        self.value_matrix = nn.Linear(embed_dim, model_dim)\n",
    "        xavier_uniform_(self.value_matrix.weight)\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim, num_heads=1)\n",
    "        \n",
    "    def forward(self, inputs, attention_mask):\n",
    "        \n",
    "        # 輸入一個項目向量，透過三個可學習的參數矩陣，得到計算所需要的 q,k,v\n",
    "        q = self.query_matrix(inputs)\n",
    "        k = self.key_matrix(inputs)\n",
    "        v = self.value_matrix(inputs)\n",
    "        \n",
    "        attn_output, attn_output_weight = self.multihead_attn(q, k, v, key_padding_mask=attention_mask.transpose(0,1))\n",
    "        \n",
    "        output_mean = torch.tensor([[0 for _ in range(MODEL_DIMENSION)] for _ in range(len(attention_mask))], dtype=torch.float).to(device)\n",
    "        for i, cart in enumerate(attention_mask):\n",
    "            for j, mask in enumerate(cart):\n",
    "                if mask == False:\n",
    "                    output_mean[i] = attn_output[i][j] # 使用最後一個項目作為輸出\n",
    "        basket_embedding = output_mean\n",
    "        \n",
    "        return basket_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3043def",
   "metadata": {},
   "source": [
    "   # Basket Size Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b8530b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearTransformation(nn.Module):\n",
    "    def __init__(self, model_dim, input_dim:int=1):\n",
    "        super(LinearTransformation, self).__init__()\n",
    "        self.embed = torch.nn.Linear(input_dim, model_dim)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        #print(inputs.type())\n",
    "        #output = torch.tensor([self.embed(basket_size) for basket_size in inputs], dtype=torch.float).to(device)\n",
    "         #print(output1)\n",
    "        #for basket_size in inputs:\n",
    "            #print(basket_size.type())\n",
    "            #basket_size = basket_size.to(torch.float)\n",
    "        output = torch.tensor([(self.embed(basket_size)).tolist() for basket_size in inputs], dtype=torch.float).to(device)\n",
    "        #print(output)\n",
    "        #print(output.type())\n",
    "        #output = self.embed(output1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cd99b7",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc0ed90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model:int, dropout, maxlen:int=500):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        # den 是把10000^(2i/d_model)取log_e，前面加負號是求倒數\n",
    "        den = torch.exp(-torch.arange(0, d_model, 2) * math.log(10000) / d_model)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros(maxlen, d_model)#.to(device)\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos*den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos*den)\n",
    "        \n",
    "        pos_embedding = pos_embedding.unsqueeze(0)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\"pos_embedding\", pos_embedding)\n",
    "        \n",
    "    def forward(self, token_embedding):\n",
    "        #interleave(token_embedding, 1)\n",
    "        return self.dropout(token_embedding+ self.pos_embedding[:, :token_embedding.size(1), :])\n",
    "    \n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, d_model, num_heads=8, num_layers=6):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.pe = PositionalEncoding(d_model=d_model, dropout=0.5, maxlen=max_cart_count)\n",
    "        # 創建 Transformer 模型\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=num_heads),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "    \n",
    "    def forward(self, baskets_embedding):\n",
    "        baskets_embedding_pe = self.pe(baskets_embedding)\n",
    "        \n",
    "        # 購物籃padding的遮罩\n",
    "        padding_mask = ~baskets_embedding.sum(dim=-1).ne(0).transpose(0,1)\n",
    "        \n",
    "        output = self.transformer(baskets_embedding_pe.to(torch.float32), src_key_padding_mask=padding_mask.to(torch.float32))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdd237c",
   "metadata": {},
   "source": [
    "# MLP層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8fb5303",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPLayer(nn.Module):\n",
    "    def __init__(self, embed_dim, hidden_dim, items_dim):\n",
    "        super(MLPLayer, self).__init__()\n",
    "        self.hidden = nn.Linear(embed_dim, hidden_dim) # 隱藏層\n",
    "        xavier_uniform_(self.hidden.weight)\n",
    "        self.norm = nn.BatchNorm1d(hidden_dim, momentum=0.03)\n",
    "        self.activate = nn.ReLU() # ?\n",
    "        self.output = nn.Linear(hidden_dim, items_dim) # 輸出層\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        y = self.activate(self.norm(self.hidden(inputs)))\n",
    "        return self.output(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f948580d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPLayerForSize(nn.Module):\n",
    "    def __init__(self, embed_dim, hidden_dim):\n",
    "        super(MLPLayerForSize, self).__init__()\n",
    "        self.hidden = nn.Linear(embed_dim, hidden_dim) #隱藏層\n",
    "        xavier_uniform_(self.hidden.weight)\n",
    "        self.norm = nn.BatchNorm1d(hidden_dim, momentum=0.03)\n",
    "        self.activate = nn.ReLU()\n",
    "        self.output = nn.Linear(hidden_dim, 1) # 輸出層\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        k = self.activate(self.norm(self.hidden(inputs)))\n",
    "        return self.activate(self.output(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afdd949",
   "metadata": {},
   "source": [
    "# 損失函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a2f39835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE\n",
    "def mean_square_error(predictions, target):\n",
    "    print(\"target\", target)\n",
    "    targets = torch.tensor(target, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "    print(\"targets\", targets)\n",
    "    print(\"prediction_size:\", predictions.size())\n",
    "    print(\"targets_size:\", targets.size())\n",
    "    loss = F.mse_loss(predictions, targets)\n",
    "    print(\"loss_size:\", loss.size())\n",
    "    print(\"size_loss\", loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "578a7e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_entropy_loss\n",
    "def cross_entropy_loss(predictions, targets):\n",
    "    # 創建稀疏張量的索引和值\n",
    "    indices = []\n",
    "    values = []\n",
    "    for i, t in enumerate(targets):\n",
    "        for v in t:\n",
    "            indices.append([i, v])\n",
    "            values.append(1)\n",
    "\n",
    "    # 創建稀疏張量\n",
    "    sparse_targets = torch.sparse_coo_tensor(indices=torch.tensor(indices).t(),\n",
    "                                             values=torch.tensor(values, dtype=torch.float16),\n",
    "                                             size=(len(targets), items_count), device=device)\n",
    "    sparse_targets = sparse_targets.to_dense()\n",
    "    \n",
    "    loss = F.binary_cross_entropy_with_logits(predictions, sparse_targets)\n",
    "    print(\"entropy_size\", loss.size())\n",
    "    print(\"entropy_loss\", loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aefe4a",
   "metadata": {},
   "source": [
    "# 評估指標"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "308ff8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def format_metric(result_dict):\n",
    "#     assert type(result_dict) == dict\n",
    "#     format_str = []\n",
    "#     metrics = np.unique([k.split('@')[0] for k in result_dict.keys()])\n",
    "#     topks = np.unique([int(k.split('@')[1]) for k in result_dict.keys()])\n",
    "#     for topk in np.sort(topks):\n",
    "#         for metric in np.sort(metrics):\n",
    "#             name = '{}@{}'.format(metric, topk)\n",
    "#             m = result_dict[name]           \n",
    "#             if type(m) is float or type(m) is float or type(m) is np.float32 or type(m) is np.float64:\n",
    "#                 format_str.append('{}: {:<.4f}'.format(name, m))\n",
    "#             elif type(m) is int or type(m) is int or type(m) is np.int32 or type(m) is np.int64:\n",
    "#                 format_str.append('{}: {}'.format(name, m))\n",
    "#     return ', '.join(format_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "2f56054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_metric(result_dict):\n",
    "    assert type(result_dict) == dict\n",
    "    format_str = []\n",
    "    metrics = np.unique([k for k in result_dict.keys()])\n",
    "    #topks = np.unique([int(k.split('@')[1]) for k in result_dict.keys()])\n",
    "    #for topk in np.sort(topks):\n",
    "    for metric in np.sort(metrics):\n",
    "        name = '{}'.format(metric)\n",
    "        m = result_dict[name]\n",
    "        if type(m) is float or type(m) is float or type(m) is np.float32 or type(m) is np.float64:\n",
    "            format_str.append('{}: {:<.4f}'.format(name, m))\n",
    "        elif type(m) is int or type(m) is int or type(m) is np.int32 or type(m) is np.int64:\n",
    "            format_str.append('{}: {}'.format(name, m))\n",
    "    return ', '.join(format_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96a4cfe",
   "metadata": {},
   "source": [
    "## HR@K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "ced1b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_hr_at_k(predictions, labels_list, k_list):\n",
    "#     # 將預測機率矩陣轉換為 PyTorch 張量。\n",
    "#     predictions = torch.from_numpy(np.array(predictions, dtype=np.float32)).to(device)\n",
    "#     num_users = len(labels_list)\n",
    "#     evaluations = dict()\n",
    "#     for k in k_list:\n",
    "#         HR = []\n",
    "#         for i in range(num_users):\n",
    "#             # 將用戶 i 的真實標籤轉換為 PyTorch 張量。\n",
    "#             labels = torch.from_numpy(np.array(labels_list[i], dtype=np.int64)).to(device)\n",
    "#             # 計算用戶 i 在預測機率矩陣中機率最高的 K 個項目的索引。\n",
    "#             top_k_item_indices = torch.topk(predictions[i], k)[1]\n",
    "#             # 將用戶 i 在預測機率矩陣中機率最高的 K 個項目的索引和其真實標籤向量的交集，即為預測正確的項目數量。\n",
    "#             correct_num = torch.sum(torch.sum(torch.eq(top_k_item_indices, labels.unsqueeze(1)), dim=1))\n",
    "#             # 計算 HR。\n",
    "#             HR.append( correct_num.cpu()/len(labels) )\n",
    "#         # 計算 HR@K 分數。\n",
    "#         hr_at_k = np.mean(HR)\n",
    "#         key = '{}@{}'.format('HR',k)\n",
    "#         evaluations[key]=hr_at_k\n",
    "#     return evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa92db9d",
   "metadata": {},
   "source": [
    "## F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f7cca32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_f1_score_at_k(predictions, labels_list, k_list):\n",
    "#     \"\"\"\n",
    "#     計算 F1-score@K。\n",
    "\n",
    "#     Args:\n",
    "#         predictions: 二維的預測機率矩陣，大小為 [num_users, num_items]。\n",
    "#         labels_list: 一個包含每個用戶真實標籤的列表，其中每個列表的大小不同。\n",
    "#         k: 計算 F1-score@K 的 K 值。\n",
    "\n",
    "#     Returns:\n",
    "#         F1-score@K 分數。\n",
    "#     \"\"\"\n",
    "#     # 將預測機率矩陣轉換為 PyTorch 張量。\n",
    "#     predictions = torch.from_numpy(np.array(predictions, dtype=np.float32))#.to('cuda')\n",
    "#     num_users = len(labels_list)\n",
    "#     f1_score_at_k_eval = dict()\n",
    "    \n",
    "#     for k in k_list:\n",
    "#         f1_score_sum = 0.0\n",
    "#         for i in range(num_users):\n",
    "#                 # 將用戶 i 的真實標籤轉換為 PyTorch 張量。\n",
    "#                 labels = torch.from_numpy(np.array(labels_list[i], dtype=np.int64))#.to('cuda')\n",
    "#                 # 計算用戶 i 在預測機率矩陣中機率最高的 K 個項目的索引。\n",
    "#                 top_k_item_labels = torch.topk(predictions[i], k)[1]\n",
    "#                 # 計算用戶 i 的真實標籤和預測標籤的交集。 # TP\n",
    "#                 true_positives = torch.sum(torch.sum(torch.eq(top_k_item_labels, labels.unsqueeze(1)).to(torch.float32), dim=1)).item()\n",
    "#                 # 計算用戶 i 的真實標籤和預測標籤的並集。\n",
    "#                 predicted_positives = k # TP+FP\n",
    "#                 actual_positives = len(labels) # TP+FN\n",
    "#                 if actual_positives == 0:\n",
    "#                     precision = 0.0\n",
    "#                     recall = 0.0\n",
    "#                 else:\n",
    "#                     precision = true_positives / predicted_positives\n",
    "#                     recall = true_positives / actual_positives\n",
    "#                 # 計算 F1-score。\n",
    "#                 if precision + recall == 0:\n",
    "#                     f1_score = 0.0\n",
    "#                 else:\n",
    "#                     f1_score = 2 * precision * recall / (precision + recall)\n",
    "#                 f1_score_sum += f1_score\n",
    "#         # 計算平均 F1-score@K 分數。\n",
    "#         f1_score_at_k = f1_score_sum / float(num_users)\n",
    "#         key = '{}@{}'.format('F1-score',k)\n",
    "#         f1_score_at_k_eval[key]=f1_score_at_k\n",
    "        \n",
    "#     return f1_score_at_k_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "384bd870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1_score_at_k(predictions, labels_list, k):\n",
    "    \"\"\"\n",
    "    計算 F1-score@K。\n",
    "\n",
    "    Args:\n",
    "        predictions: 二維的預測機率矩陣，大小為 [num_users, num_items]。\n",
    "        labels_list: 一個包含每個用戶真實標籤的列表，其中每個列表的大小不同。\n",
    "        k: 計算 F1-score@K 的 K 值。\n",
    "\n",
    "    Returns:\n",
    "        F1-score@K 分數。\n",
    "    \"\"\"\n",
    "    # 將預測機率矩陣轉換為 PyTorch 張量。\n",
    "    predictions = torch.from_numpy(np.array(predictions, dtype=np.float32))#.to('cuda')\n",
    "    num_users = len(labels_list)\n",
    "    f1_score_at_k_eval = dict()\n",
    "    \n",
    "\n",
    "    f1_score_sum = 0.0\n",
    "    for i in range(num_users):\n",
    "            # 將用戶 i 的真實標籤轉換為 PyTorch 張量。\n",
    "            labels = torch.from_numpy(np.array(labels_list[i], dtype=np.int64))#.to('cuda')\n",
    "            # 計算用戶 i 在預測機率矩陣中機率最高的 K 個項目的索引。\n",
    "            top_k_item_labels = torch.topk(predictions[i], k)[1]\n",
    "            # 計算用戶 i 的真實標籤和預測標籤的交集。 # TP\n",
    "            true_positives = torch.sum(torch.sum(torch.eq(top_k_item_labels, labels.unsqueeze(1)).to(torch.float32), dim=1)).item()\n",
    "            # 計算用戶 i 的真實標籤和預測標籤的並集。\n",
    "            predicted_positives = k # TP+FP\n",
    "            actual_positives = len(labels) # TP+FN\n",
    "            if actual_positives == 0:\n",
    "                precision = 0.0\n",
    "                recall = 0.0\n",
    "            else:\n",
    "                precision = true_positives / predicted_positives\n",
    "                recall = true_positives / actual_positives\n",
    "            # 計算 F1-score。\n",
    "            if precision + recall == 0:\n",
    "                f1_score = 0.0\n",
    "            else:\n",
    "                f1_score = 2 * precision * recall / (precision + recall)\n",
    "            f1_score_sum += f1_score\n",
    "    # 計算平均 F1-score@K 分數。\n",
    "    f1_score_at_k = f1_score_sum / float(num_users)\n",
    "    key = '{}'.format('F1-score')\n",
    "    f1_score_at_k_eval[key]=f1_score_at_k\n",
    "        \n",
    "    return f1_score_at_k_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506ff404",
   "metadata": {},
   "source": [
    "## NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "4c566188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NDCG@K\n",
    "# def calculate_ndcg_at_k(predictions, labels_list, k_list):\n",
    "#     # 將預測機率矩陣轉換為 PyTorch 張量。\n",
    "#     predictions = torch.from_numpy(np.array(predictions, dtype=np.float32))\n",
    "#     num_users = len(labels_list)\n",
    "#     ndcg_at_k_eval = dict()\n",
    "    \n",
    "#     for k in k_list:\n",
    "#         ndcg_sum = 0.0\n",
    "#         for i in range(num_users):\n",
    "#             # 將用戶 i 的真實標籤轉換為 PyTorch 張量。\n",
    "#             labels = torch.from_numpy(np.array(labels_list[i], dtype=np.int64))\n",
    "#             # 計算用戶 i 在預測機率矩陣中機率最高的 K 個項目的索引=標籤。\n",
    "#             top_k_item_labels = torch.topk(predictions[i], k)[1]\n",
    "#             # 計算 DCG@K。\n",
    "#             dcg_at_k = torch.sum(torch.div(1.0, torch.log2(torch.arange(k, dtype=torch.float32) + 2)) * (torch.eq(top_k_item_labels, labels.unsqueeze(1)).to(torch.float32) ))\n",
    "#             # 計算 IDCG@K。\n",
    "#             idcg_at_k = torch.sum(torch.div(1.0, torch.log2(torch.arange(min(k, len(labels)), dtype=torch.float32) + 2)))\n",
    "#             # 計算 NDCG@K。\n",
    "#             ndcg_at_k = dcg_at_k / idcg_at_k\n",
    "#             ndcg_sum += ndcg_at_k.item()\n",
    "#         # 計算平均 NDCG@K 分數。\n",
    "#         ndcg_at_k = ndcg_sum / float(num_users)\n",
    "#         key = '{}@{}'.format('NDCG',k)\n",
    "#         ndcg_at_k_eval[key]=ndcg_at_k\n",
    "        \n",
    "\n",
    "#     return ndcg_at_k_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "d523d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NDCG@K\n",
    "def calculate_ndcg_at_k(predictions, labels_list, k):\n",
    "    # 將預測機率矩陣轉換為 PyTorch 張量。\n",
    "    predictions = torch.from_numpy(np.array(predictions, dtype=np.float32))\n",
    "    num_users = len(labels_list)\n",
    "    ndcg_at_k_eval = dict()\n",
    "    \n",
    "    ndcg_sum = 0.0\n",
    "    for i in range(num_users):\n",
    "        # 將用戶 i 的真實標籤轉換為 PyTorch 張量。\n",
    "        labels = torch.from_numpy(np.array(labels_list[i], dtype=np.int64))\n",
    "        # 計算用戶 i 在預測機率矩陣中機率最高的 K 個項目的索引=標籤。\n",
    "        top_k_item_labels = torch.topk(predictions[i], k)[1]\n",
    "        # 計算 DCG@K。\n",
    "        dcg_at_k = torch.sum(torch.div(1.0, torch.log2(torch.arange(k, dtype=torch.float32) + 2)) * (torch.eq(top_k_item_labels, labels.unsqueeze(1)).to(torch.float32) ))\n",
    "        # 計算 IDCG@K。\n",
    "        #idcg_at_k = torch.sum(torch.div(1.0, torch.log2(torch.arange(min(k, len(labels)), dtype=torch.float32) + 2)))\n",
    "        idcg_at_k = torch.sum(torch.div(1.0, torch.log2(torch.arange(len(labels), dtype=torch.float32) + 2)))\n",
    "        # 計算 NDCG@K。\n",
    "        ndcg_at_k = dcg_at_k / idcg_at_k\n",
    "        ndcg_sum += ndcg_at_k.item()\n",
    "    # 計算平均 NDCG@K 分數。\n",
    "    ndcg_at_k = ndcg_sum / float(num_users)\n",
    "    key = '{}'.format('NDCG')\n",
    "    ndcg_at_k_eval[key]=ndcg_at_k\n",
    "        \n",
    "\n",
    "    return ndcg_at_k_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458759fa",
   "metadata": {},
   "source": [
    "## MPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "9160a9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #MRR\n",
    "# def calculate_MRR(predictions, labels_list):\n",
    "#     reciprocal_ranks = []\n",
    "#     # 將預測機率矩陣轉換為 numpy 數組。\n",
    "#     predictions = np.array(predictions, dtype=np.float32)\n",
    "#     # 預先排序預測結果（降序）\n",
    "#     sorted_predictions = np.argsort(predictions)[:,::-1]\n",
    "#     # 遍歷每個查詢的預測結果與目標結果\n",
    "#     for pred, targets in zip(sorted_predictions, labels_list):\n",
    "#         # 將目標結果轉換為集合\n",
    "#         target_set = set(targets.numpy())\n",
    "#         # 尋找目標的排名\n",
    "#         rank = next((i + 1 for i, p in enumerate(pred) if p in target_set), 0)\n",
    "#         # 計算倒數排名\n",
    "#         reciprocal_rank = 1 / rank if rank > 0 else 0\n",
    "#         reciprocal_ranks.append(reciprocal_rank)\n",
    "#     # 計算 MRR\n",
    "#     mrr_score = sum(reciprocal_ranks) / len(reciprocal_ranks)\n",
    "#     return mrr_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5f7b84",
   "metadata": {},
   "source": [
    "## MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "074334ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #MAP\n",
    "# def calculate_MAP(predictions, labels_list):\n",
    "#     average_precisions = []\n",
    "#     # 將預測機率矩陣轉換為 numpy 數組。\n",
    "#     predictions = np.array(predictions, dtype=np.float32)\n",
    "#     # 預先排序預測結果（降序）\n",
    "#     sorted_predictions = np.argsort(predictions)[:,::-1]\n",
    "#     # 遍歷每個查詢的預測結果與目標結果\n",
    "#     for pred, targets in zip(sorted_predictions, labels_list):\n",
    "#         # 將目標結果轉換為集合\n",
    "#         target_set = set(targets.numpy())\n",
    "#         # 計算查詢的精確度\n",
    "#         precision = []\n",
    "#         hits = 0\n",
    "#         for i, p in enumerate(pred):\n",
    "#             if p in target_set:\n",
    "#                 hits += 1\n",
    "#                 precision.append(hits / (i + 1))\n",
    "#         # 計算平均精確度\n",
    "#         if precision:\n",
    "#             average_precision = sum(precision) / len(precision)\n",
    "#             average_precisions.append(average_precision)\n",
    "#     # 計算 MAP\n",
    "#     map_score = sum(average_precisions) / len(average_precisions)\n",
    "#     return map_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213301db",
   "metadata": {},
   "source": [
    "# 訓練&測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "5d503206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練模型\n",
    "def train_model():\n",
    "    my_model.train()\n",
    "    loss_list = []\n",
    "    \n",
    "    for batch_idx, (userID, basket_input, basket_label, size_input, size_label, offsets) in enumerate(tqdm(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        basket_output, size_output, indices = my_model(basket_input, size_input, offsets[1:])\n",
    "        # 計算損失\n",
    "        loss = ALPHA * mean_square_error(size_output, size_label) + (1-ALPHA) * cross_entropy_loss(basket_output , basket_label)\n",
    "        loss_list.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (batch_idx%100 == 0) or (batch_idx == len(train_dataloader)-1) :\n",
    "            percentage = (100. * batch_idx/len(train_dataloader))\n",
    "            print(f'Epoch {epoch}: {percentage:.0f}% , Loss: {loss.item():.6f}')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            basket_output = torch.from_numpy(np.array(basket_output.cpu(), dtype=np.float32))\n",
    "            if batch_idx==0:\n",
    "                basket_outputs = basket_output\n",
    "                labels_list = basket_label\n",
    "            else:\n",
    "                basket_outputs = torch.cat( (basket_outputs, basket_output ),-2 )\n",
    "                labels_list = labels_list + basket_label\n",
    "\n",
    "    with torch.no_grad():\n",
    "        evaluations = calculate_hr_at_k(outputs, labels_list, [5,10,20,50])\n",
    "        res_str = '(' + format_metric(evaluations) + ')'\n",
    "        print(f\"                      {res_str}\\n\")\n",
    "\n",
    "        evaluations = calculate_f1_score_at_k(outputs, labels_list, [5,10,20,50])\n",
    "        res_str = '(' + format_metric(evaluations) + ')'\n",
    "        print(f\"                      {res_str}\\n\")\n",
    "\n",
    "        evaluations = calculate_ndcg_at_k(outputs, labels_list, [5,10,20,50])\n",
    "        res_str = '(' + format_metric(evaluations) + ')'\n",
    "        print(f\"                      {res_str}\\n\")\n",
    "        \n",
    "        mrr_score = calculate_MRR( outputs, labels_list )\n",
    "        print(f'MRR: {mrr_score}')\n",
    "        map_score = calculate_MAP( outputs, labels_list )\n",
    "        print(f'MAP: {map_score}')\n",
    "\n",
    "    return torch.mean(torch.tensor(loss_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "b0799869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 驗證模型\n",
    "def evaluate_model():\n",
    "    my_model.eval()\n",
    "    loss_list = []\n",
    "    \n",
    "    for batch_idx, (userID, train_input, labels, offsets) in enumerate(tqdm(valid_dataloader)):\n",
    "        output, indices = my_model(train_input, offsets[1:])\n",
    "        # 計算損失\n",
    "        loss = cross_entropy_loss( output ,labels) \n",
    "        loss_list.append(loss.item())\n",
    "        with torch.no_grad():\n",
    "            output = torch.from_numpy(np.array(output.cpu(), dtype=np.float32))\n",
    "            if batch_idx==0:\n",
    "                outputs = output\n",
    "                labels_list = labels\n",
    "            else:\n",
    "                outputs = torch.cat( (outputs, output ),-2 )\n",
    "                labels_list = labels_list + labels\n",
    "\n",
    "    with torch.no_grad():\n",
    "        evaluations = calculate_hr_at_k(outputs, labels_list, [5,10,20,50])\n",
    "        hr_5_rec = evaluations['HR@5']\n",
    "        res_str = '(' + format_metric(evaluations) + ')'\n",
    "        print(f\"                      {res_str}\\n\")\n",
    "\n",
    "        evaluations = calculate_f1_score_at_k(outputs, labels_list, [5,10,20,50])\n",
    "        res_str = '(' + format_metric(evaluations) + ')'\n",
    "        print(f\"                      {res_str}\\n\")\n",
    "\n",
    "        evaluations = calculate_ndcg_at_k(outputs, labels_list, [5,10,20,50])\n",
    "        res_str = '(' + format_metric(evaluations) + ')'\n",
    "        print(f\"                      {res_str}\\n\")\n",
    "        \n",
    "        mrr_score = calculate_MRR( outputs, labels_list )\n",
    "        print(f'MRR: {mrr_score}')\n",
    "        map_score = calculate_MAP( outputs, labels_list )\n",
    "        print(f'MAP: {map_score}')\n",
    "\n",
    "    return torch.mean(torch.tensor(loss_list)),hr_5_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "5e8d7319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試模型\n",
    "def test_model():\n",
    "    my_model.eval()\n",
    "    loss_list = []\n",
    "    \n",
    "    for batch_idx, (userID, train_input, labels, offsets) in enumerate(tqdm(test_dataloader)):\n",
    "        output, indices = my_model(train_input, offsets[1:])\n",
    "        # 計算損失\n",
    "        loss = cross_entropy_loss( output ,labels)\n",
    "        loss_list.append(loss.item())\n",
    "        with torch.no_grad():\n",
    "            output = torch.from_numpy(np.array(output.cpu(), dtype=np.float32))\n",
    "            if batch_idx==0:\n",
    "                outputs = output\n",
    "                labels_list = labels\n",
    "            else:\n",
    "                outputs = torch.cat( (outputs, output ),-2 )\n",
    "                labels_list = labels_list + labels\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hr_evaluations = calculate_hr_at_k(outputs, labels_list, [5,10,20,50])\n",
    "        hr_5_rec = hr_evaluations['HR@5']\n",
    "        hr_10_rec = hr_evaluations['HR@10']\n",
    "        hr_20_rec = hr_evaluations['HR@20']\n",
    "        hr_50_rec = hr_evaluations['HR@50']\n",
    "        hr_list = [hr_5_rec, hr_10_rec, hr_20_rec, hr_50_rec]\n",
    "        res_str = '(' + format_metric(hr_evaluations) + ')'\n",
    "        print(f\"                      {res_str}\\n\")\n",
    "\n",
    "        f1_evaluations = calculate_f1_score_at_k(outputs, labels_list, [5,10,20,50])\n",
    "        f1_5_rec = f1_evaluations['F1-score@5']\n",
    "        f1_10_rec = f1_evaluations['F1-score@10']\n",
    "        f1_20_rec = f1_evaluations['F1-score@20']\n",
    "        f1_50_rec = f1_evaluations['F1-score@50']\n",
    "        f1_list = [f1_5_rec, f1_10_rec, f1_20_rec, f1_50_rec]\n",
    "        res_str = '(' + format_metric(f1_evaluations) + ')'\n",
    "        print(f\"                      {res_str}\\n\")\n",
    "\n",
    "        ndcg_evaluations = calculate_ndcg_at_k(outputs, labels_list, [5,10,20,50])\n",
    "        ndcg_5_rec = ndcg_evaluations['NDCG@5']\n",
    "        ndcg_10_rec = ndcg_evaluations['NDCG@10']\n",
    "        ndcg_20_rec = ndcg_evaluations['NDCG@20']\n",
    "        ndcg_50_rec = ndcg_evaluations['NDCG@50']\n",
    "        ndcg_list = [ndcg_5_rec, ndcg_10_rec, ndcg_20_rec, ndcg_50_rec]\n",
    "        res_str = '(' + format_metric(ndcg_evaluations) + ')'\n",
    "        print(f\"                      {res_str}\\n\")\n",
    "        \n",
    "        mrr_score = calculate_MRR( outputs, labels_list )\n",
    "        print(f'MRR: {mrr_score}')\n",
    "        map_score = calculate_MAP( outputs, labels_list )\n",
    "        print(f'MAP: {map_score}')\n",
    "\n",
    "    return torch.mean(torch.tensor(loss_list)),hr_5_rec,hr_list,f1_list,ndcg_list, mrr_score, map_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abc8fbc",
   "metadata": {},
   "source": [
    "# 完整模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "5ad81bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items_count= 15764\n",
      "tensor([1.7128e-03, 1.1418e-03, 2.4169e-02,  ..., 6.3436e-05, 6.3436e-05,\n",
      "        6.3436e-05], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 項目總數\n",
    "items_count = TaFeng_confidences_array.shape[0]\n",
    "print(\"items_count=\",items_count)\n",
    "# 項目出現次數\n",
    "items_frq = Counter(TaFeng[\"NEW_ITEM_ID\"])\n",
    "# 計算每個項目出現的比例: items_frq/items_count\n",
    "item_weight = torch.tensor( np.array( list(items_frq.values()) )/items_count ).to(device)\n",
    "print(item_weight) # 按照new_item_id順序排列"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975d9e58",
   "metadata": {},
   "source": [
    "## 加上信賴度矩陣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "5d571c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0370, 0.0370,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0556, 0.0000, 0.0556,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0026, 0.0026, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "       device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 信賴度矩陣\n",
    "confidences_array = torch.tensor(TaFeng_confidences_array,dtype=torch.float64).to(device)\n",
    "confidences_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "36b974d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Interleave(tensor1, tensor2):\n",
    "    result = torch.stack((tensor1, tensor2), dim=1)\n",
    "    Interleave_tensor = torch.reshape(result, (-1, MODEL_DIMENSION))\n",
    "    #print(\"test3\", Interleave_tensor)\n",
    "    #print(Interleave_tensor.device)\n",
    "    return (Interleave_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "b00066a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel01(nn.Module):\n",
    "    def __init__(self, embed_dim, model_dim, hidden_dim, items_count):\n",
    "        super(MyModel01, self).__init__()\n",
    "        self.model_dim = model_dim\n",
    "        self.embedding = nn.Embedding.from_pretrained(weights, freeze=False)\n",
    "        self.embedding.requires_grad = True\n",
    "        self.attn = SelfAttention(embed_dim=embed_dim ,model_dim=model_dim)\n",
    "        self.linear_transform = LinearTransformation(model_dim = model_dim)\n",
    "        self.model_encoder = TransformerEncoder(d_model=model_dim , num_heads=NUM_HEAD, num_layers=NUM_LAYER)\n",
    "        self.mlp = MLPLayer(model_dim, hidden_dim, items_count ) # 嵌入維度、隱藏層維度、總項目數量\n",
    "        self.sizemlp = MLPLayerForSize(model_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        \n",
    "    def forward(self, basket_input, size_input ,lengths):\n",
    "        \n",
    "        inputs, attention_mask = [], []\n",
    "\n",
    "        # 為每個用戶的購物籃加上 padding跟 mask\n",
    "        for user in basket_input:\n",
    "            # 將購物籃項目 ID 轉換為嵌入向量\n",
    "            batch_features = [ self.embedding(torch.tensor(cart).to(device)) for cart in user ]\n",
    "            # 進行 padding\n",
    "            #print(\"obatch_size\", batch_features)\n",
    "            batch_features = rnn_utils.pad_sequence(batch_features, batch_first=True, padding_value=0)\n",
    "            # 購物籃中項目的遮罩\n",
    "            mask = ~batch_features.sum(dim=-1).ne(0)\n",
    "            #print(\"batch_size\", batch_features.size())\n",
    "            inputs.append(batch_features)\n",
    "            attention_mask.append(mask)\n",
    "\n",
    "            \n",
    "        # 進入自注意力，輸出形狀為 (BATCH_SIZE, basket_size, embed_dim)\n",
    "        basket_embedding_list = []\n",
    "        for i,user_inputs in enumerate(inputs):\n",
    "            test = self.attn(user_inputs,attention_mask[i])\n",
    "            #basket_embedding_list.append(test)\n",
    "            #print(\"test_size\", test.size())\n",
    "            #print(\"test\", test)\n",
    "            \n",
    "            test2 = self.linear_transform(torch.tensor([[float(_)] for _ in size_input[i]]).to(device))\n",
    "            #size_embedding_list.append(test2)\n",
    "            #print(\"test\", test.size())\n",
    "            #print(\"test2\", test2.size())\n",
    "            basket_embedding = Interleave(test, test2)\n",
    "            #print(\"test3\", basket_embedding.size())\n",
    "            basket_embedding_list.append(basket_embedding)\n",
    "            #print(\"test2_size\", test2.size())\n",
    "            #bs_encoder = self.linear_transform()\n",
    "            #basket_embedding_list.append(self.attn(user_inputs,attention_mask[i]))\n",
    "            \n",
    "        \n",
    "        \n",
    "        # 進行購物籃的 padding\n",
    "        input_seq = rnn_utils.pad_sequence(basket_embedding_list, batch_first=True, padding_value=0)\n",
    "        #print(input_seq.size())\n",
    "        \n",
    "        \n",
    "        # 進入Transformer\n",
    "        basket_embed = self.model_encoder(input_seq.to(device))\n",
    "        \n",
    "        B_s_list = []\n",
    "        for i, b in enumerate(basket_embed):\n",
    "            basket_size = len(attention_mask[i])\n",
    "            B_s = b[basket_size-1]  # 取得最後一個購物籃向量\n",
    "            B_s_list.append(B_s)\n",
    "            \n",
    "        # SIZE_MLP\n",
    "        k = self.sizemlp(torch.stack(B_s_list, dim=0))\n",
    "        print(\"k\", k)\n",
    "        # 進入MLP層\n",
    "        p = self.mlp(torch.stack(B_s_list, dim=0))\n",
    "        pc = (self.relu(p.to(torch.float64))+1e-8) @ confidences_array\n",
    "        pw = torch.mul( p, item_weight )\n",
    "        p_ = torch.mul(BETA, torch.add(pc,pw)) + torch.mul(1-BETA, p.to(torch.float64))\n",
    "        y = p_\n",
    "        Y,indices = torch.topk(y, k=10)\n",
    "        return y, k, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "88bf8d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel01(\n",
       "  (embedding): Embedding(15764, 32)\n",
       "  (attn): SelfAttention(\n",
       "    (query_matrix): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (key_matrix): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (value_matrix): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (multihead_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (linear_transform): LinearTransformation(\n",
       "    (embed): Linear(in_features=1, out_features=32, bias=True)\n",
       "  )\n",
       "  (model_encoder): TransformerEncoder(\n",
       "    (pe): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (transformer): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=32, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=32, bias=True)\n",
       "          (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mlp): MLPLayer(\n",
       "    (hidden): Linear(in_features=32, out_features=128, bias=True)\n",
       "    (norm): BatchNorm1d(128, eps=1e-05, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activate): ReLU()\n",
       "    (output): Linear(in_features=128, out_features=15764, bias=True)\n",
       "  )\n",
       "  (sizemlp): MLPLayerForSize(\n",
       "    (hidden): Linear(in_features=32, out_features=128, bias=True)\n",
       "    (norm): BatchNorm1d(128, eps=1e-05, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (activate): ReLU()\n",
       "    (output): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = MyModel01(embed_dim=EMBEDDING_DIMENSION, model_dim=MODEL_DIMENSION,  hidden_dim=HIDDEN_DIMENSION,  items_count=items_count ).to(device)\n",
    "optimizer = torch.optim.Adam(my_model.parameters(),lr=LEARNING_RATE)\n",
    "my_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "dc547691",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/932 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k tensor([[0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.2547],\n",
      "        [0.0000],\n",
      "        [0.6390]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "target [tensor(31), tensor(34), tensor(9), tensor(4), tensor(12), tensor(8), tensor(8), tensor(3)]\n",
      "targets tensor([[31.],\n",
      "        [34.],\n",
      "        [ 9.],\n",
      "        [ 4.],\n",
      "        [12.],\n",
      "        [ 8.],\n",
      "        [ 8.],\n",
      "        [ 3.]], device='cuda:0')\n",
      "prediction_size: torch.Size([8, 1])\n",
      "targets_size: torch.Size([8, 1])\n",
      "loss_size: torch.Size([])\n",
      "size_loss tensor(310.9454, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "entropy_size torch.Size([])\n",
      "entropy_loss tensor(1.4697, device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Epoch 1: 0% , Loss: 94.312920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'output' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[234], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m( \u001b[38;5;241m1\u001b[39m  , EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m ):\n\u001b[1;32m----> 8\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train_model()\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss=\u001b[39m\u001b[38;5;124m\"\u001b[39m,train_loss)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "Cell \u001b[1;32mIn[226], line 20\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpercentage\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.0f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% , Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 20\u001b[0m     output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39marray(output\u001b[38;5;241m.\u001b[39mcpu(), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_idx\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     22\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m output\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'output' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "# 消融實驗 w/o Item2vec and Confidence\n",
    "# MyModel02\n",
    "# 固定參數: epochs35 Transformer_layer=4 batch_size=8 embedding_size=32 hidden_size=128 lr=0.0001 num_layer=4 num_head=4\n",
    "\n",
    "results = []\n",
    "\n",
    "for epoch in range( 1  , EPOCHS + 1 ):\n",
    "    train_loss = train_model()\n",
    "    print(\"train_loss=\",train_loss)\n",
    "    print('-'*20)\n",
    "    val_loss,hr_5_rec = evaluate_model()\n",
    "    print(\"val_loss=\",val_loss)\n",
    "    print('-' * 20)\n",
    "    test_loss,test_hr_5_rec,hr_list,f1_list,ndcg_list, mrr_score, map_score = test_model()\n",
    "    print('-' * 20)\n",
    "    result = [epoch] + hr_list + f1_list + ndcg_list + [mrr_score,map_score] + [val_loss.item()]\n",
    "    results.append(result)\n",
    "    print(results)\n",
    "    print('-' * 89)\n",
    "    \n",
    "    collected = gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "record_df = pd.DataFrame(results,columns=['Epoch','HR@5', 'HR@10', 'HR@20', 'HR@50', 'F1-score@5', 'F1-score@10', 'F1-score@20', 'F1-score@50',\n",
    "                           'NDCG@5', 'NDCG@10', 'NDCG@20', 'NDCG@50','MRR','MAP','val_loss'])\n",
    "record_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff67314",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[0,0,0],[4,5,0]])\n",
    "mask = a.sum(dim=-1)\n",
    "print(mask)\n",
    "print(mask.ne(0).transpose(0,1))\n",
    "# 目的:相讓用戶的某個購物籃大小相同，再用key padding mask去遮padding的部分\n",
    "# 某位user的shape - (batch_size, cart的數量, item的維度)\n",
    "# 因為你padding所以代表某位用戶的cart裡面的item數量都相同\n",
    "# 代表可能是\n",
    "# [[[0,1,...,30,31],  ->第一個購物籃\n",
    "#   [32,33...,62,63],\n",
    "#   [0,0,...,0,0],],\n",
    "#  [[0,1,...,30,31],  ->第二個購物籃\n",
    "#   [32,33...,62,63],\n",
    "#   [64,65,...,94,95]]]\n",
    "# 所以sum(dim=-1)代表[0,0,0,0]是padding的\n",
    "# .ne為not equal代表不等於0:  0:false  不是0:true\n",
    "# ~代表false->true, true->false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da1be2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.zeros((2, 4))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57304f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建兩個矩陣\n",
    "tensor1 = torch.tensor([[1, 2, 3],\n",
    "                        [4, 5, 6]])\n",
    "\n",
    "tensor2 = torch.tensor([[7, 8, 9],\n",
    "                        [10, 11, 12]])\n",
    "print(tensor1.size())\n",
    "# 按照行進行交叉穿插\n",
    "\n",
    "# 按照行進行交叉穿插\n",
    "result_column = torch.stack([(tensor1[:, i].tolist(), tensor2[:, i].tolist()) for i in range(tensor1.size(1))]).t().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb4b116",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = torch.stack((tensor1, tensor2), dim=1).numpy()\n",
    "#tensor3 = torch.from_numpy(a.reshape(-1,3)) # 3是 EMBEDDING_DIMENSION\n",
    "a = torch.stack((tensor1, tensor2), dim=1)\n",
    "tensor3= torch.reshape(a, (-1, 3))\n",
    "\n",
    "print(tensor3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd3eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply2(x):\n",
    "    print(x)\n",
    "    alist = []\n",
    "    alist.append(x)\n",
    "    #print(alist)\n",
    "    return alist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85d0442",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2]\n",
    "a = torch.tensor([[_] for _ in a])\n",
    "c = multiply2(a)\n",
    "#c = torch.tensor([multiply2(x) for x in a])\n",
    "\n",
    "#a\n",
    "#c\n",
    "\n",
    "#print(np.array(a).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf27932",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (userID, basket_input, basket_label, size_input, size_label, offsets) in enumerate(train_dataloader):\n",
    "    print(basket_input)\n",
    "    #for user in basket_input:\n",
    "        #print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8274dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\"a\",\"b\",\"c\",\"d\"]\n",
    "a= \", \".join(a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48554d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(1., 6.)\n",
    "torch.topk(x, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00fbeb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
